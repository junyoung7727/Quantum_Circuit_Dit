#!/usr/bin/env python3
"""
Mega Job 600ê°œ ì–‘ì íšŒë¡œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
- ëª¨ë“  íšŒë¡œë¥¼ í•œ ë²ˆì˜ ê±°ëŒ€í•œ jobìœ¼ë¡œ ì œì¶œ
- ìµœëŒ€ íš¨ìœ¨ì„±ê³¼ ìµœì†Œ ëŒ€ê¸° ì‹œê°„
"""

import os
import sys
import time
import gc
import json
import pandas as pd
import numpy as np
from datetime import datetime
from tqdm import tqdm
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from main import simplify_circuit_info, calculate_expressibility_from_ibm_results, calculate_entropy_expressibility_from_ibm_results
from quantum_base import QuantumCircuitBase
from ibm_backend import IBMQuantumBackend
from qiskit import QuantumCircuit, transpile
from qiskit.circuit import Parameter

def generate_all_circuits():
    """config ì„¤ì •ì„ í™œìš©í•œ 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ í…ŒìŠ¤íŠ¸ìš© íšŒë¡œ ìƒì„±"""
    from config import config
    
    # configì—ì„œ ê¸°ë³¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    circuit_ranges = config.get_circuit_ranges()
    
    # 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ í…ŒìŠ¤íŠ¸ ì„¤ì •
    n_qubits_list = [5, 7 ,10, 15, 20, 60, 127] 
    depth_list = [1, 2, 3, 4]   
    two_qubit_ratios = [0.1, 0.3, 0.5]  # 3ê°œ ë¹„ìœ¨ (10%, 30%, 50%)
    circuits_per_config = 10   # ê° ì„¤ì •ë‹¹ 10ê°œ íšŒë¡œ (í• ë‹¹ëŸ‰ ì ˆì•½)
    
    # ì´ íšŒë¡œ ìˆ˜ ê³„ì‚°: 3 Ã— 3 Ã— 3 Ã— 10 = 270ê°œ
    total_circuits = len(n_qubits_list) * len(depth_list) * len(two_qubit_ratios) * circuits_per_config
    print(f"ğŸ”§ í…ŒìŠ¤íŠ¸ìš© 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ í…ŒìŠ¤íŠ¸ {total_circuits}ê°œ íšŒë¡œ ìƒì„± ì¤‘...")
    print(f"   íë¹— ìˆ˜: {n_qubits_list}")
    print(f"   íšŒë¡œ ê¹Šì´: {depth_list}")
    print(f"   2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨: {[f'{r:.1%}' for r in two_qubit_ratios]}")
    print(f"   ê° ì„¤ì •ë‹¹ íšŒë¡œ ìˆ˜: {circuits_per_config} (í• ë‹¹ëŸ‰ ì ˆì•½ ëª¨ë“œ)")
    
    base_circuit = QuantumCircuitBase()
    all_circuits = []
    
    circuit_id = 0
    for n_qubits in n_qubits_list:
        for depth in depth_list:
            for two_qubit_ratio in two_qubit_ratios:
                print(f"  ìƒì„± ì¤‘: {n_qubits}íë¹—, ê¹Šì´{depth}, 2íë¹—ë¹„ìœ¨{two_qubit_ratio:.1%} - {circuits_per_config}ê°œ íšŒë¡œ")
                
                for i in range(circuits_per_config):
                    # íšŒë¡œ ìƒì„± (2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ ì§€ì •)
                    circuit_info = base_circuit.generate_random_circuit(
                        n_qubits=n_qubits,
                        depth=depth,
                        strategy="hardware_efficient",
                        seed=circuit_id + i,  # ì¬í˜„ ê°€ëŠ¥í•œ ì‹œë“œ
                        two_qubit_ratio=two_qubit_ratio  # 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ ì„¤ì •
                    )
                    
                    # íšŒë¡œ ID ë° ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    circuit_info["circuit_id"] = circuit_id
                    circuit_info["config_group"] = f"q{n_qubits}_d{depth}_r{int(two_qubit_ratio*100)}"
                    circuit_info["two_qubit_ratio_target"] = two_qubit_ratio
                    
                    all_circuits.append(circuit_info)
                    circuit_id += 1
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                progress = (circuit_id / total_circuits) * 100
                print(f"    ì§„í–‰ë¥ : {progress:.1f}% ({circuit_id}/{total_circuits})")
    
    print(f"âœ… ì´ {len(all_circuits)}ê°œ íšŒë¡œ ìƒì„± ì™„ë£Œ!")
    
    # ì„¤ì •ë³„ íšŒë¡œ ìˆ˜ ìš”ì•½
    print("\nğŸ“Š ì„¤ì •ë³„ íšŒë¡œ ìˆ˜ ìš”ì•½:")
    config_counts = {}
    for circuit in all_circuits:
        config_group = circuit["config_group"]
        if config_group in config_counts:
            config_counts[config_group] = 1
        else:
            config_counts[config_group] = 1
    
    for config_group, count in sorted(config_counts.items()):
        print(f"  {config_group}: {count}ê°œ")
    
    return all_circuits

def convert_to_qiskit_circuits(all_circuits, ibm_backend):
    """ëª¨ë“  íšŒë¡œë¥¼ Qiskit íšŒë¡œë¡œ ë³€í™˜"""
    from qiskit import QuantumCircuit, transpile
    
    print("ğŸ”„ Qiskit íšŒë¡œë¡œ ë³€í™˜ ë° íŠ¸ëœìŠ¤íŒŒì¼ ì¤‘...")
    
    qiskit_circuits = []
    circuit_metadata = []
    
    for i, circuit_data in enumerate(tqdm(all_circuits, desc="íšŒë¡œ ë³€í™˜")):
        try:
            circuit_info = circuit_data['circuit_info']
            n_qubits = circuit_info["n_qubits"]
            gates = circuit_info["gates"]
            wires_list = circuit_info["wires_list"]
            params_idx = circuit_info["params_idx"]
            params = circuit_info["params"]
            
            # íë¹— ìˆ˜ ì œí•œ (ë°±ì—”ë“œ í•œê³„)
            max_backend_qubits = ibm_backend.backend.configuration().n_qubits
            if n_qubits > max_backend_qubits:
                n_qubits = max_backend_qubits
            
            # Qiskit ì–‘ì íšŒë¡œ ìƒì„± (U + Uâ€ )
            qc = QuantumCircuit(n_qubits, n_qubits)
            
            # ìˆœë°©í–¥ íšŒë¡œ (U) ì ìš©
            for j, (gate, wires) in enumerate(zip(gates, wires_list)):
                if any(w >= n_qubits for w in wires):
                    continue
                    
                if gate == "H":
                    qc.h(wires[0])
                elif gate == "X":
                    qc.x(wires[0])
                elif gate == "Y":
                    qc.y(wires[0])
                elif gate == "Z":
                    qc.z(wires[0])
                elif gate == "S":
                    qc.s(wires[0])
                elif gate == "T":
                    qc.t(wires[0])
                elif gate == "RZ":
                    # íŒŒë¼ë¯¸í„° ì°¾ê¸°
                    param_value = None
                    for k, idx in enumerate(params_idx):
                        if idx == j:
                            param_value = params[k]
                            break
                    if param_value is not None:
                        qc.rz(param_value, wires[0])
                elif gate == "CNOT":
                    if len(wires) >= 2:
                        qc.cx(wires[0], wires[1])
            
            # ì—­ë°©í–¥ íšŒë¡œ (Uâ€ ) ì ìš©
            for j in range(len(gates)-1, -1, -1):
                gate = gates[j]
                wires = wires_list[j]
                
                if any(w >= n_qubits for w in wires):
                    continue
                
                if gate == "H":
                    qc.h(wires[0])
                elif gate == "X":
                    qc.x(wires[0])
                elif gate == "Y":
                    qc.y(wires[0])
                elif gate == "Z":
                    qc.z(wires[0])
                elif gate == "S":
                    qc.sdg(wires[0])
                elif gate == "T":
                    qc.tdg(wires[0])
                elif gate == "RZ":
                    # íŒŒë¼ë¯¸í„° ì°¾ê¸°
                    param_value = None
                    for k, idx in enumerate(params_idx):
                        if idx == j:
                            param_value = params[k]
                            break
                    if param_value is not None:
                        qc.rz(-param_value, wires[0])
                elif gate == "CNOT":
                    if len(wires) >= 2:
                        qc.cx(wires[0], wires[1])
            
            # ì¸¡ì • ì¶”ê°€
            qc.measure_all()
            
            # íŠ¸ëœìŠ¤íŒŒì¼
            qc_transpiled = transpile(qc, backend=ibm_backend.backend, optimization_level=0)
            
            # íšŒë¡œ íŠ¹ì„± ê³„ì‚° (íŠ¸ëœìŠ¤íŒŒì¼ ì •ë³´ í¬í•¨)
            circuit_properties = calculate_quantum_properties(circuit_info, qc_transpiled)
            
            # ë©”íƒ€ë°ì´í„°ì— íšŒë¡œ íŠ¹ì„± ì¶”ê°€
            enhanced_metadata = circuit_data.copy()
            enhanced_metadata['circuit_properties'] = circuit_properties
            
            qiskit_circuits.append(qc_transpiled)
            circuit_metadata.append(enhanced_metadata)
            
        except Exception as e:
            print(f"âš ï¸ íšŒë¡œ {i} ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
    
    print(f"âœ… {len(qiskit_circuits)}ê°œ íšŒë¡œ ë³€í™˜ ì™„ë£Œ")
    return qiskit_circuits, circuit_metadata

def run_mega_job(qiskit_circuits, circuit_metadata, ibm_backend, shots=128, circuit_shot_requirements=None):
    """
    IBM ë°±ì—”ë“œì—ì„œ ëŒ€ëŸ‰ íšŒë¡œë¥¼ í•œ ë²ˆì˜ jobìœ¼ë¡œ ì‹¤í–‰ (ì§„ì§œ ë°°ì¹˜ ì‹¤í–‰)
    
    Args:
        qiskit_circuits (list): Qiskit íšŒë¡œ ëª©ë¡ (ì‹¤ì œë¡œëŠ” circuit_info ëª©ë¡)
        circuit_metadata (list): íšŒë¡œ ë©”íƒ€ë°ì´í„° ëª©ë¡
        ibm_backend (IBMQuantumBackend): IBM ë°±ì—”ë“œ ê°ì²´
        shots (int): ê¸°ë³¸ íšŒë¡œë‹¹ ìƒ· ìˆ˜
        circuit_shot_requirements (list): ê° íšŒë¡œë³„ í•„ìš” ìƒ· ìˆ˜ ëª©ë¡ (ì„ íƒì‚¬í•­)
        
    Returns:
        list: ì‹¤í–‰ ê²°ê³¼ ëª©ë¡
    """
    if not qiskit_circuits:
        print("âš ï¸ ì‹¤í–‰í•  íšŒë¡œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # íšŒë¡œë³„ ìƒ· ìˆ˜ ê²°ì •
    if circuit_shot_requirements and len(circuit_shot_requirements) == len(qiskit_circuits):
        total_shots = sum(circuit_shot_requirements)
        print(f"\nğŸš€ IBM ë°±ì—”ë“œì—ì„œ {len(qiskit_circuits)}ê°œ íšŒë¡œë¥¼ í•œ ë²ˆì˜ ë°°ì¹˜ jobìœ¼ë¡œ ì‹¤í–‰ ì‹œì‘")
        print(f"   íšŒë¡œë³„ ê°œë³„ ìƒ· ìˆ˜: Config ì„¤ì •ì— ë”°ë¼ ë‹¤ë¦„")
        print(f"   ë°°ì¹˜ ì´ ì‹¤í–‰ ìˆ˜: {total_shots:,}")
    else:
        total_shots = len(qiskit_circuits) * shots
        print(f"\nğŸš€ IBM ë°±ì—”ë“œì—ì„œ {len(qiskit_circuits)}ê°œ íšŒë¡œë¥¼ í•œ ë²ˆì˜ ë°°ì¹˜ jobìœ¼ë¡œ ì‹¤í–‰ ì‹œì‘")
        print(f"   íšŒë¡œë‹¹ ê³ ì • ìƒ· ìˆ˜: {shots:,}")
        print(f"   ë°°ì¹˜ ì´ ì‹¤í–‰ ìˆ˜: {total_shots:,}")
    
    print(f"   ì˜ˆìƒ ë°ì´í„° í’ˆì§ˆ: {'ğŸŸ¢ ë†’ìŒ' if total_shots/len(qiskit_circuits) >= 1024 else 'ğŸŸ¡ ë³´í†µ' if total_shots/len(qiskit_circuits) >= 512 else 'ğŸ”´ ë‚®ìŒ'}")
    
    start_time = time.time()
    
    try:
        # ëª¨ë“  íšŒë¡œë¥¼ Qiskit íšŒë¡œë¡œ ë³€í™˜
        print("ğŸ“‹ ë°°ì¹˜ íšŒë¡œ ì¤€ë¹„ ì¤‘...")
        qiskit_circuit_list = []
        
        for circuit_idx, circuit_info in enumerate(qiskit_circuits):
            try:
                # circuit_infoì—ì„œ Qiskit íšŒë¡œ ìƒì„±
                n_qubits = circuit_info["n_qubits"]
                gates = circuit_info["gates"]
                wires_list = circuit_info["wires_list"]
                params_idx = circuit_info["params_idx"]
                params = circuit_info["params"]
                
                # íë¹— ìˆ˜ ì œí•œ (ë°±ì—”ë“œ í•œê³„)
                max_backend_qubits = ibm_backend.backend.configuration().n_qubits
                if n_qubits > max_backend_qubits:
                    n_qubits = max_backend_qubits
                
                # Qiskit ì–‘ì íšŒë¡œ ìƒì„± (U + Uâ€ )
                from qiskit import QuantumCircuit
                qc = QuantumCircuit(n_qubits, n_qubits)
                
                # ìˆœë°©í–¥ íšŒë¡œ (U) ì ìš©
                for j, (gate, wires) in enumerate(zip(gates, wires_list)):
                    if any(w >= n_qubits for w in wires):
                        continue
                        
                    if gate == "H":
                        qc.h(wires[0])
                    elif gate == "X":
                        qc.x(wires[0])
                    elif gate == "Y":
                        qc.y(wires[0])
                    elif gate == "Z":
                        qc.z(wires[0])
                    elif gate == "S":
                        qc.s(wires[0])
                    elif gate == "T":
                        qc.t(wires[0])
                    elif gate == "RZ":
                        # íŒŒë¼ë¯¸í„° ì°¾ê¸°
                        param_value = None
                        for k, idx in enumerate(params_idx):
                            if idx == j:
                                param_value = params[k]
                                break
                        if param_value is not None:
                            qc.rz(param_value, wires[0])
                    elif gate == "CNOT":
                        if len(wires) >= 2:
                            qc.cx(wires[0], wires[1])
                
                # ì—­ë°©í–¥ íšŒë¡œ (Uâ€ ) ì ìš©
                for j in range(len(gates)-1, -1, -1):
                    gate = gates[j]
                    wires = wires_list[j]
                    
                    if any(w >= n_qubits for w in wires):
                        continue
                    
                    if gate == "H":
                        qc.h(wires[0])
                    elif gate == "X":
                        qc.x(wires[0])
                    elif gate == "Y":
                        qc.y(wires[0])
                    elif gate == "Z":
                        qc.z(wires[0])
                    elif gate == "S":
                        qc.sdg(wires[0])
                    elif gate == "T":
                        qc.tdg(wires[0])
                    elif gate == "RZ":
                        # íŒŒë¼ë¯¸í„° ì°¾ê¸°
                        param_value = None
                        for k, idx in enumerate(params_idx):
                            if idx == j:
                                param_value = params[k]
                                break
                        if param_value is not None:
                            qc.rz(-param_value, wires[0])
                    elif gate == "CNOT":
                        if len(wires) >= 2:
                            qc.cx(wires[0], wires[1])
                
                # ì¸¡ì • ì¶”ê°€
                qc.measure_all()
                
                # íŠ¸ëœìŠ¤íŒŒì¼
                from qiskit import transpile
                qc_transpiled = transpile(qc, backend=ibm_backend.backend, optimization_level=0)
                qiskit_circuit_list.append(qc_transpiled)
                
                if (circuit_idx + 1) % 100 == 0:
                    print(f"   íšŒë¡œ ë³€í™˜ ì§„í–‰ë¥ : {circuit_idx + 1}/{len(qiskit_circuits)}")
                
            except Exception as e:
                print(f"âš ï¸ íšŒë¡œ {circuit_idx} ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
                continue
        
        print(f"âœ… {len(qiskit_circuit_list)}ê°œ íšŒë¡œ ë³€í™˜ ì™„ë£Œ")
        
        if not qiskit_circuit_list:
            print("âŒ ë³€í™˜ëœ íšŒë¡œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # IBM ë°±ì—”ë“œì—ì„œ ë°°ì¹˜ ì‹¤í–‰
        print("ğŸš€ IBM ë°±ì—”ë“œì—ì„œ ë°°ì¹˜ job ì œì¶œ ì¤‘...")
        
        # ê° íšŒë¡œë³„ ìƒ· ìˆ˜ ì„¤ì •
        if circuit_shot_requirements:
            # íšŒë¡œë³„ ë‹¤ë¥¸ ìƒ· ìˆ˜ (í˜„ì¬ IBM APIëŠ” ëª¨ë“  íšŒë¡œì— ë™ì¼í•œ ìƒ· ìˆ˜ë§Œ ì§€ì›)
            # í‰ê·  ìƒ· ìˆ˜ ì‚¬ìš©
            avg_shots = int(sum(circuit_shot_requirements) / len(circuit_shot_requirements))
            print(f"   íšŒë¡œë³„ í‰ê·  ìƒ· ìˆ˜: {avg_shots}")
        else:
            avg_shots = shots
        
        # IBM Runtime Sampler ì‚¬ìš©
        from qiskit_ibm_runtime import SamplerV2 as Sampler
        
        sampler = Sampler(mode=ibm_backend.backend)
        
        # ë°°ì¹˜ ì‹¤í–‰
        print(f"   {len(qiskit_circuit_list)}ê°œ íšŒë¡œë¥¼ {avg_shots} ìƒ·ìœ¼ë¡œ ì‹¤í–‰ ì¤‘...")
        job = sampler.run(qiskit_circuit_list, shots=avg_shots)
        
        print(f"   Job ID: {job.job_id()}")
        print("   ê²°ê³¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")
        
        # ê²°ê³¼ ëŒ€ê¸°
        result = job.result()
        
        print("âœ… ë°°ì¹˜ ì‹¤í–‰ ì™„ë£Œ!")
        
        # ê²°ê³¼ ì²˜ë¦¬
        print("ğŸ“Š ê²°ê³¼ ì²˜ë¦¬ ì¤‘...")
        results = []
        
        for circuit_idx, (pub_result, circuit_info) in enumerate(zip(result, qiskit_circuits)):
            try:
                # ì¸¡ì • ê²°ê³¼ ì¶”ì¶œ
                counts = pub_result.data.meas.get_counts()
                
                # íšŒë¡œ ì •ë³´
                n_qubits = circuit_info["n_qubits"]
                
                # ë¹„íŠ¸ì—´ ì²˜ë¦¬
                processed_counts = {}
                total_counts = sum(counts.values())
                
                for bit_str, count in counts.items():
                    if len(bit_str) > n_qubits:
                        bit_str = bit_str[:n_qubits]
                    elif len(bit_str) < n_qubits:
                        bit_str = bit_str.zfill(n_qubits)
                    
                    if bit_str in processed_counts:
                        processed_counts[bit_str] += count
                    else:
                        processed_counts[bit_str] = count
                
                # í”¼ë¸ë¦¬í‹° ê³„ì‚°
                zero_state = '0' * n_qubits
                zero_count = processed_counts.get(zero_state, 0)
                zero_state_probability = zero_count / total_counts if total_counts > 0 else 0
                
                # ì˜¤ë¥˜ìœ¨ ê³„ì‚°
                from main import calculate_error_rates
                error_rates = calculate_error_rates(
                    processed_counts,
                    n_qubits,
                    total_counts
                )
                
                # Robust í”¼ë¸ë¦¬í‹° ê³„ì‚°
                from main import calculate_robust_fidelity
                robust_fidelity = calculate_robust_fidelity(
                    processed_counts,
                    n_qubits,
                    total_counts
                )
                
                # ì‹¤í–‰ ê²°ê³¼ êµ¬ì„±
                execution_result = {
                    "zero_state_probability": zero_state_probability,
                    "measurement_counts": processed_counts,
                    "measured_states": total_counts,
                    "significant_states": len(processed_counts),
                    "zero_state_count": zero_count,
                    "error_rates": error_rates,
                    "robust_fidelity": robust_fidelity,
                    "backend": ibm_backend.backend.name
                }
                
                # í‘œí˜„ë ¥ ê³„ì‚° (Classical Shadow + ì—”íŠ¸ë¡œí”¼ ë°©ë²•)
                try:
                    # ExpressibilityCalculator ì‚¬ìš©
                    from expressibility_calculator import ExpressibilityCalculator, calculate_entropy_expressibility_from_ibm_results
                    calculator = ExpressibilityCalculator()
                    
                    # measurement_countsê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
                    if isinstance(processed_counts, dict) and processed_counts:
                        # 1. Classical Shadow ê¸°ë°˜ í‘œí˜„ë ¥ ê³„ì‚°
                        try:
                            # ì•ˆì „í•œ Classical Shadow ê³„ì‚°
                            classical_shadow_expressibility = None
                            
                            # ì¸¡ì • ê²°ê³¼ê°€ ì¶©ë¶„í•œì§€ í™•ì¸
                            if len(processed_counts) > 0 and sum(processed_counts.values()) > 10:
                                # IBM ì¸¡ì • ê²°ê³¼ë¥¼ Classical Shadow í˜•íƒœë¡œ ë³€í™˜
                                from main import convert_ibm_results_to_shadow
                                shadow_data = convert_ibm_results_to_shadow(processed_counts, circuit_info["n_qubits"])
                                
                                # Shadow ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
                                if (isinstance(shadow_data, dict) and 
                                    "measurements" in shadow_data and 
                                    "bases" in shadow_data and
                                    isinstance(shadow_data["measurements"], list) and
                                    isinstance(shadow_data["bases"], list) and
                                    len(shadow_data["measurements"]) > 0 and
                                    len(shadow_data["bases"]) > 0):
                                    
                                    shadow_data_list = [shadow_data]
                                    
                                    # ExpressibilityCalculatorì˜ ë©”ì„œë“œ ì‚¬ìš©
                                    estimated_moments = calculator._estimate_pauli_expectations_from_shadows(shadow_data_list, circuit_info["n_qubits"])
                                    haar_moments = calculator._get_haar_pauli_expectations(circuit_info["n_qubits"])
                                    
                                    # ê±°ë¦¬ ê³„ì‚°
                                    distance = calculator._calculate_shadow_distance(estimated_moments, haar_moments)
                                    
                                    classical_shadow_expressibility = {
                                        "n_qubits": circuit_info["n_qubits"],
                                        "samples": 1,
                                        "metric": "classical_shadow",
                                        "distance": distance,
                                        "confidence_interval": [max(0, distance * 0.5), distance * 1.5],
                                        "run_time": 0.1,
                                        "normalized_distance": distance / (2**min(circuit_info["n_qubits"], 10)) if distance > 0 else 0.0,
                                        "source": "ibm_execution_simplified"
                                    }
                                else:
                                    print(f"    âš ï¸ íšŒë¡œ {circuit_idx} Shadow ë°ì´í„° êµ¬ì¡° ì˜¤ë¥˜")
                            else:
                                print(f"    âš ï¸ íšŒë¡œ {circuit_idx} ì¸¡ì • ë°ì´í„° ë¶€ì¡±")
                                
                        except Exception as e:
                            print(f"    âš ï¸ íšŒë¡œ {circuit_idx} Classical Shadow í‘œí˜„ë ¥ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
                            classical_shadow_expressibility = None
                        
                        # 2. ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í‘œí˜„ë ¥ ê³„ì‚°
                        try:
                            entropy_expressibility = calculate_entropy_expressibility_from_ibm_results(
                                processed_counts, circuit_info["n_qubits"]
                            )
                        except Exception as e:
                            print(f"    âš ï¸ íšŒë¡œ {circuit_idx} ì—”íŠ¸ë¡œí”¼ í‘œí˜„ë ¥ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
                            entropy_expressibility = None
                        
                        # ë‘ ë°©ë²•ì˜ ê²°ê³¼ë¥¼ ëª¨ë‘ ì €ì¥
                        execution_result["expressibility"] = {
                            "classical_shadow": classical_shadow_expressibility,
                            "entropy_based": entropy_expressibility
                        }
                    else:
                        execution_result["expressibility"] = {
                            "classical_shadow": None,
                            "entropy_based": None
                        }
                except Exception as e:
                    print(f"    âš ï¸ íšŒë¡œ {circuit_idx} í‘œí˜„ë ¥ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
                    execution_result["expressibility"] = {
                        "classical_shadow": None,
                        "entropy_based": None
                    }
                
                # ê²°ê³¼ ì¡°í•©
                result_data = {
                    "circuit_info": circuit_info,
                    "execution_result": execution_result,
                    "circuit_idx": circuit_idx,
                    "shots_used": avg_shots,
                    "execution_time": time.time() - start_time
                }
                
                results.append(result_data)
                
                if (circuit_idx + 1) % 100 == 0:
                    print(f"   ê²°ê³¼ ì²˜ë¦¬ ì§„í–‰ë¥ : {circuit_idx + 1}/{len(qiskit_circuits)}")
                
            except Exception as e:
                print(f"âš ï¸ íšŒë¡œ {circuit_idx} ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                continue
        
        execution_time = time.time() - start_time
        
        print(f"\nğŸ‰ ë°°ì¹˜ ì‹¤í–‰ ì™„ë£Œ!")
        print(f"   ì´ ì‹¤í–‰ ì‹œê°„: {execution_time:.1f}ì´ˆ")
        print(f"   ì„±ê³µí•œ íšŒë¡œ: {len(results)}/{len(qiskit_circuits)}")
        print(f"   ì„±ê³µë¥ : {len(results)/len(qiskit_circuits)*100:.1f}%")
        print(f"   ì‹¤ì œ ì‚¬ìš©ëœ ì´ ìƒ· ìˆ˜: {len(results) * avg_shots:,}")
        
        return results
        
    except Exception as e:
        print(f"âš ï¸ ë°°ì¹˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return []

def process_mega_results(result, circuit_metadata, execution_time):
    """mega job ê²°ê³¼ ì²˜ë¦¬ - ì‹¤ì œ ì¸¡ì • ë°ì´í„°ë§Œ ì‚¬ìš©"""
    print("\nğŸ“Š ê²°ê³¼ ì²˜ë¦¬ ì¤‘...")
    
    all_results = []
    training_circuits = []
    
    # í‘œí˜„ë ¥ ê³„ì‚°ì„ ìœ„í•œ ê¸°ë³¸ íšŒë¡œ ê°ì²´
    base_circuit = QuantumCircuitBase()
    
    for i, (circuit_result, circuit_data) in enumerate(zip(result, circuit_metadata)):
        try:
            circuit_info = circuit_data['circuit_info']
            n_qubits = circuit_info["n_qubits"]
            
            # ì¸¡ì • ê²°ê³¼ ì¶”ì¶œ
            counts = {}
            
            # Qiskit 2.0+ APIì—ì„œ ê²°ê³¼ ì¶”ì¶œ
            if hasattr(circuit_result, 'data') and hasattr(circuit_result.data, 'meas'):
                bit_array = circuit_result.data.meas
                if hasattr(bit_array, 'get_counts'):
                    counts_dict = bit_array.get_counts()
                    
                    # ë¹„íŠ¸ì—´ ì²˜ë¦¬
                    sparse_counts = {}
                    for bit_str, count in counts_dict.items():
                        if len(bit_str) > n_qubits:
                            bit_str = bit_str[:n_qubits]
                        elif len(bit_str) < n_qubits:
                            bit_str = bit_str.zfill(n_qubits)
                        
                        if bit_str in sparse_counts:
                            sparse_counts[bit_str] += count
                        else:
                            sparse_counts[bit_str] = count
                    
                    counts = sparse_counts
            
            if not counts:
                print(f"âš ï¸ íšŒë¡œ {i} ê²°ê³¼ ì¶”ì¶œ ì‹¤íŒ¨")
                continue
            
            # ì‹¤ì œ ì¸¡ì • ê²°ê³¼ ê¸°ë°˜ í†µê³„
            measurement_stats = calculate_measurement_statistics(counts, n_qubits)
            
            # í”¼ë¸ë¦¬í‹° ê³„ì‚° (ì‹¤ì œ ì¸¡ì • ê²°ê³¼)
            total_counts = sum(counts.values())
            zero_state = '0' * n_qubits
            zero_count = counts.get(zero_state, 0)
            fidelity = zero_count / total_counts if total_counts > 0 else 0
            
            # Robust Fidelity ê³„ì‚° (ë…¸ì´ì¦ˆ í—ˆìš©)
            robust_fidelity = calculate_robust_fidelity_mega(counts, n_qubits, total_counts)
            
            # í‘œí˜„ë ¥ ê³„ì‚° (IBM ì¸¡ì • ê²°ê³¼ ê¸°ë°˜)
            if i % 50 == 0:
                print(f"  íšŒë¡œ {i+1}/{len(result)} í‘œí˜„ë ¥ ê³„ì‚° ì¤‘...")
            
            try:
                # 1. Classical Shadow ê¸°ë°˜ í‘œí˜„ë ¥ ê³„ì‚°
                expressibility_result = calculate_expressibility_from_ibm_results(
                    base_circuit, 
                    circuit_info,
                    counts,  # ì¸¡ì • ê²°ê³¼ ì‚¬ìš©
                    n_qubits,
                    samples=1  # ë‹¨ì¼ ì¸¡ì • ê¸°ë°˜
                )
                
                # í‘œí˜„ë ¥ ê´€ë ¨ ì§€í‘œ ì¶”ì¶œ
                expr_distance = expressibility_result.get("distance", 0)
                expr_normalized = expressibility_result.get("normalized_distance", 0)
                
            except Exception as e:
                print(f"âš ï¸ íšŒë¡œ {i} Classical Shadow í‘œí˜„ë ¥ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
                expressibility_result = None
                expr_distance = 0
                expr_normalized = 0
            
            # 2. ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í‘œí˜„ë ¥ ê³„ì‚° (ìƒˆë¡œìš´ ë°©ì‹)
            try:
                # QuantumCircuitBaseë¥¼ ì‚¬ìš©í•˜ì—¬ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
                entropy_value = base_circuit.calculate_entropy(counts)
                
                # ê²°ê³¼ í¬ë§·íŒ… (ì´ì „ ë²„ì „ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì‚¬í•œ êµ¬ì¡° ìœ ì§€)
                entropy_expressibility_result = {
                    "expressibility_value": entropy_value,
                    "entropy": entropy_value,
                    "method": "measurement_entropy"
                }
                
                # ì´ì „ ë²„ì „ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
                entropy_expr_value = entropy_value
                
            except Exception as e:
                print(f"âš ï¸ íšŒë¡œ {i} ì—”íŠ¸ë¡œí”¼ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
                entropy_expressibility_result = None
                entropy_expr_value = 0
                angle_entropy = 0
                distance_entropy = 0
            
            # íšŒë¡œ êµ¬ì¡° íŠ¹ì„± ê°€ì ¸ì˜¤ê¸°
            circuit_properties = circuit_data.get('circuit_properties', {})
            structural_props = circuit_properties.get('structural_properties', {})
            param_props = circuit_properties.get('parameter_properties', {})
            hardware_props = circuit_properties.get('hardware_context', {})
            
            # íŠ¸ëœìŠ¤í¬ë¨¸ ì…ë ¥ìš© ì„ë² ë”© ìƒì„±
            circuit_sequence = circuit_properties.get('circuit_sequence', [])
            circuit_embedding = create_circuit_embedding(circuit_sequence)
            
            # AI í›ˆë ¨ìš© ë°ì´í„° êµ¬ì¡° (ì‹¤ì œ ë°ì´í„°ë§Œ)
            training_circuit = {
                "circuit_id": circuit_data['circuit_id'],
                "ansatz_data": {
                    "circuit_info": simplify_circuit_info(circuit_info),
                    "execution_results": {
                        "fidelity": fidelity,
                        "robust_fidelity": robust_fidelity,
                        "measured_states": total_counts,
                        "significant_states": len(counts),
                        "zero_state_count": zero_count,
                        "backend": "ibm_mega_job"
                    },
                    "expressibility": expressibility_result,
                    "entropy_expressibility": entropy_expressibility_result,
                    "metadata": circuit_data['metadata']
                },
                "features": {
                    # ê¸°ë³¸ íšŒë¡œ ì •ë³´
                    "n_qubits": circuit_data['n_qubits'],
                    "depth": circuit_data['depth'],
                    "gate_count": len(circuit_info.get("gates", [])),
                    
                    # ì‹¤ì œ ì¸¡ì • ê²°ê³¼
                    "fidelity": fidelity,
                    "robust_fidelity": robust_fidelity,
                    "expressibility_distance": expr_distance,
                    "normalized_expressibility": expr_normalized,
                        
                    # ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í‘œí˜„ë ¥ ì§€í‘œ
                    "entropy_expressibility": entropy_expr_value,
                    "angle_entropy": angle_entropy,
                    "distance_entropy": distance_entropy,
                        
                    # ì¸¡ì • í†µê³„ (ì‹¤ì œ ë°ì´í„°)
                    **measurement_stats,
                    
                    # íšŒë¡œ êµ¬ì¡° íŠ¹ì„± (ì‹¤ì œ ë°ì´í„°)
                    **structural_props,
                    
                    # íŒŒë¼ë¯¸í„° íŠ¹ì„± (ì‹¤ì œ ë°ì´í„°)
                    **param_props,
                    
                    # í•˜ë“œì›¨ì–´ ìµœì í™” ê²°ê³¼ (ì‹¤ì œ ë°ì´í„°)
                    **hardware_props,
                    
                    # ì‹œí€€ìŠ¤ íŠ¹ì„± (íŠ¸ëœìŠ¤í¬ë¨¸ ì¹œí™”ì )
                    **circuit_embedding.get("sequence_features", {}),
                    
                    # ì‹¤í–‰ ì •ë³´
                    "execution_time": execution_time / len(circuit_metadata)
                },
                "transformer_input": {
                    # íŠ¸ëœìŠ¤í¬ë¨¸ ì…ë ¥ìš© ì‹œí€€ìŠ¤
                    "gate_sequence": circuit_embedding.get("gate_sequence", []),
                    "qubit_sequence": circuit_embedding.get("qubit_sequence", []),
                    "param_sequence": circuit_embedding.get("param_sequence", []),
                    "gate_type_sequence": circuit_embedding.get("gate_type_sequence", [])
                },
                "labels": {
                    "complexity_class": "low" if circuit_data['n_qubits'] <= 50 else "medium" if circuit_data['n_qubits'] <= 90 else "high",
                    "depth_class": "shallow" if circuit_data['depth'] <= 2 else "deep",
                    "fidelity_class": "high" if fidelity > 0.1 else "medium" if fidelity > 0.01 else "low",
                    "robust_fidelity_class": "high" if robust_fidelity > 0.15 else "medium" if robust_fidelity > 0.05 else "low",
                    "expressibility_class": "high" if expr_normalized < 0.001 else "medium" if expr_normalized < 0.01 else "low",
                    "entropy_expressibility_class": "high" if entropy_expr_value > 4.0 else "medium" if entropy_expr_value > 2.0 else "low",
                    "angle_entropy_class": "high" if angle_entropy > 2.0 else "medium" if angle_entropy > 1.0 else "low",
                    "distance_entropy_class": "high" if distance_entropy > 2.0 else "medium" if distance_entropy > 1.0 else "low"
                }
            }
            
            training_circuits.append(training_circuit)
            
            # CSVìš© ê²°ê³¼ (í”Œë« êµ¬ì¡°)
            circuit_result_data = {
                "circuit_id": circuit_data['circuit_id'],
                "n_qubits": circuit_data['n_qubits'],
                "depth": circuit_data['depth'],
                "gate_count": len(circuit_info.get("gates", [])),
                "fidelity": fidelity,
                "robust_fidelity": robust_fidelity,
                "expressibility_distance": expr_distance,
                "normalized_expressibility": expr_normalized,
                "execution_time": execution_time / len(circuit_metadata),
                "backend": "ibm_mega_job",
                
                # ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í‘œí˜„ë ¥ ì§€í‘œ
                "entropy_expressibility": entropy_expr_value,
                "angle_entropy": angle_entropy,
                "distance_entropy": distance_entropy,
                
                # ì¸¡ì • í†µê³„
                **measurement_stats,
                
                # êµ¬ì¡° íŠ¹ì„± (ì»¤í”Œë§ íŠ¹ì„± í¬í•¨)
                **{f"struct_{k}": v for k, v in structural_props.items()},
                
                # íŒŒë¼ë¯¸í„° íŠ¹ì„±
                **{f"param_{k}": v for k, v in param_props.items()},
                
                # í•˜ë“œì›¨ì–´ íŠ¹ì„±
                **{f"hw_{k}": v for k, v in hardware_props.items()},
                
                # ì‹œí€€ìŠ¤ íŠ¹ì„± (íŠ¸ëœìŠ¤í¬ë¨¸ ì¹œí™”ì )
                **{f"seq_{k}": v for k, v in circuit_embedding.get("sequence_features", {}).items()}
            }
            
            all_results.append(circuit_result_data)
            
        except Exception as e:
            print(f"âš ï¸ íšŒë¡œ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    print(f"\nâœ… {len(all_results)}ê°œ íšŒë¡œ ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ")
    return all_results, training_circuits

def save_mega_results(all_results, training_circuits):
    """mega job ê²°ê³¼ ì €ì¥"""
    print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    results_dir = "grid_circuits/mega_results"
    training_data_dir = "grid_circuits/training_data"
    os.makedirs(results_dir, exist_ok=True)
    os.makedirs(training_data_dir, exist_ok=True)
    
    # í…ŒìŠ¤íŠ¸ ID ìƒì„±
    test_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # CSV ê²°ê³¼ ì €ì¥
    if all_results:
        results_df = pd.DataFrame(all_results)
        csv_file = os.path.join(results_dir, f"mega_job_results_{test_id}.csv")
        results_df.to_csv(csv_file, index=False)
        print(f"CSV ê²°ê³¼ ì €ì¥: {csv_file}")
        print(f"  ì´ ì»¬ëŸ¼ ìˆ˜: {len(results_df.columns)}")
        print(f"  ì£¼ìš” ì»¬ëŸ¼: fidelity, normalized_expressibility, entropy, concentration, cnot_count, etc.")
    
    # AI í›ˆë ¨ìš© ë°°ì¹˜ ì €ì¥ (100ê°œì”©)
    circuits_per_batch = 100
    batch_counter = 0
    
    for i in range(0, len(training_circuits), circuits_per_batch):
        batch_circuits = training_circuits[i:i+circuits_per_batch]
        
        # ë°°ì¹˜ í†µê³„ ê³„ì‚°
        fidelities = [c["features"]["fidelity"] for c in batch_circuits]
        robust_fidelities = [c["features"]["robust_fidelity"] for c in batch_circuits]
        expressibilities = [c["features"]["normalized_expressibility"] for c in batch_circuits]
        entropies = [c["features"]["entropy"] for c in batch_circuits]
        concentrations = [c["features"]["concentration"] for c in batch_circuits]
        
        batch_metadata = {
            "batch_id": batch_counter,
            "test_id": test_id,
            "backend": "ibm_mega_job",
            "batch_created": datetime.now().isoformat(),
            "circuits_per_batch": len(batch_circuits),
            "is_mega_job": True,
            "data_type": "real_measurement_only"
        }
        
        training_batch = {
            "metadata": batch_metadata,
            "circuits": batch_circuits,
            "statistics": {
                "total_circuits": len(batch_circuits),
                "fidelity_stats": {
                    "mean": np.mean(fidelities),
                    "std": np.std(fidelities),
                    "min": np.min(fidelities),
                    "max": np.max(fidelities)
                },
                "robust_fidelity_stats": {
                    "mean": np.mean(robust_fidelities),
                    "std": np.std(robust_fidelities),
                    "min": np.min(robust_fidelities),
                    "max": np.max(robust_fidelities)
                },
                "expressibility_stats": {
                    "mean": np.mean(expressibilities),
                    "std": np.std(expressibilities),
                    "min": np.min(expressibilities),
                    "max": np.max(expressibilities)
                },
                "entropy_stats": {
                    "mean": np.mean(entropies),
                    "std": np.std(entropies),
                    "min": np.min(entropies),
                    "max": np.max(entropies)
                },
                "concentration_stats": {
                    "mean": np.mean(concentrations),
                    "std": np.std(concentrations),
                    "min": np.min(concentrations),
                    "max": np.max(concentrations)
                }
            }
        }
        
        # ë°°ì¹˜ íŒŒì¼ ì €ì¥
        batch_filename = os.path.join(training_data_dir, f"mega_batch_{batch_counter:03d}_{test_id}.json")
        with open(batch_filename, 'w') as f:
            json.dump(training_batch, f, indent=2, default=str)
        
        # ì••ì¶• íŒŒì¼ ì €ì¥
        import gzip
        compressed_filename = batch_filename.replace('.json', '.json.gz')
        with gzip.open(compressed_filename, 'wt') as f:
            json.dump(training_batch, f, indent=1, default=str)
        
        print(f"ë°°ì¹˜ {batch_counter} ì €ì¥: {len(batch_circuits)}ê°œ íšŒë¡œ")
        print(f"  í”¼ë¸ë¦¬í‹°: {np.mean(fidelities):.4f}Â±{np.std(fidelities):.4f}")
        print(f"  Robust í”¼ë¸ë¦¬í‹°: {np.mean(robust_fidelities):.4f}Â±{np.std(robust_fidelities):.4f}")
        print(f"  í‘œí˜„ë ¥: {np.mean(expressibilities):.4f}Â±{np.std(expressibilities):.4f}")
        print(f"  ì—”íŠ¸ë¡œí”¼: {np.mean(entropies):.2f}Â±{np.std(entropies):.2f}")
        batch_counter += 1
    
    return results_df if all_results else pd.DataFrame()

def calculate_quantum_properties(circuit_info, qc_transpiled=None):
    """ì‹¤ì œ íšŒë¡œ êµ¬ì¡°ì—ì„œ ë‚˜ì˜¤ëŠ” ìˆ˜ì¹˜ì  íŠ¹ì„±ë§Œ ê³„ì‚°"""
    n_qubits = circuit_info["n_qubits"]
    gates = circuit_info["gates"]
    wires_list = circuit_info["wires_list"]
    params = circuit_info.get("params", [])
    
    # 1. íšŒë¡œ ì‹œí€€ìŠ¤ (íŠ¸ëœìŠ¤í¬ë¨¸ ì…ë ¥ìš©) - ì‹¤ì œ ê²Œì´íŠ¸ ìˆœì„œ
    circuit_sequence = []
    for i, (gate, wires) in enumerate(zip(gates, wires_list)):
        gate_info = {
            "gate": gate,
            "qubits": wires,
            "params": []
        }
        
        # ì‹¤ì œ íŒŒë¼ë¯¸í„° ê°’
        if i in circuit_info.get("params_idx", []):
            param_idx = circuit_info["params_idx"].index(i)
            if param_idx < len(params):
                gate_info["params"] = [params[param_idx]]
        
        circuit_sequence.append(gate_info)
    
    # 2. ì‹¤ì œ ê²Œì´íŠ¸ í†µê³„
    gate_counts = {}
    for gate in gates:
        gate_counts[gate] = gate_counts.get(gate, 0) + 1
    
    # 3. ì‹¤ì œ ì—°ê²°ì„± (CNOT ê²Œì´íŠ¸ ê¸°ë°˜)
    cnot_connections = set()
    for gate, wires in zip(gates, wires_list):
        if gate == "CNOT" and len(wires) >= 2:
            cnot_connections.add(tuple(sorted(wires[:2])))
    
    # 4. ì»¤í”Œë§ë§µì„ íŠ¸ëœìŠ¤í¬ë¨¸ ì¹œí™”ì  í˜•íƒœë¡œ ë³€í™˜
    coupling_map = circuit_info.get("coupling_map", [])
    coupling_features = create_coupling_features(coupling_map, n_qubits)
    
    # 5. ì‹¤ì œ íŒŒë¼ë¯¸í„° í†µê³„
    param_stats = {}
    if params:
        param_stats = {
            "param_count": len(params),
            "param_mean": np.mean(params),
            "param_std": np.std(params),
            "param_min": np.min(params),
            "param_max": np.max(params)
        }
    else:
        param_stats = {
            "param_count": 0,
            "param_mean": 0,
            "param_std": 0,
            "param_min": 0,
            "param_max": 0
        }
    
    # 6. í•˜ë“œì›¨ì–´ ìµœì í™” ê²°ê³¼ (ì‹¤ì œ íŠ¸ëœìŠ¤íŒŒì¼ ê²°ê³¼)
    hardware_context = {}
    if qc_transpiled:
        original_gate_count = len(gates)
        transpiled_gate_count = len(qc_transpiled.data)
        
        hardware_context = {
            "original_depth": circuit_info["depth"],
            "transpiled_depth": qc_transpiled.depth(),
            "original_gate_count": original_gate_count,
            "transpiled_gate_count": transpiled_gate_count,
            "gate_overhead": transpiled_gate_count / original_gate_count if original_gate_count > 0 else 1.0,
            "depth_overhead": qc_transpiled.depth() / circuit_info["depth"] if circuit_info["depth"] > 0 else 1.0
        }
    
    return {
        "circuit_sequence": circuit_sequence,
        "structural_properties": {
            "n_qubits": n_qubits,
            "depth": circuit_info["depth"],
            "total_gates": len(gates),
            "cnot_count": gate_counts.get("CNOT", 0),
            "single_qubit_gates": sum(gate_counts.get(g, 0) for g in ["H", "X", "Y", "Z", "S", "T", "RZ"]),
            "unique_gate_types": len(gate_counts),
            "cnot_connections": len(cnot_connections),
            "gate_counts": gate_counts,
            **coupling_features  # ì»¤í”Œë§ íŠ¹ì„± ì¶”ê°€
        },
        "parameter_properties": param_stats,
        "hardware_context": hardware_context
    }

def create_coupling_features(coupling_map, n_qubits):
    """ì»¤í”Œë§ë§µì„ íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ìˆ˜ì¹˜ì  íŠ¹ì„±ìœ¼ë¡œ ë³€í™˜"""
    if not coupling_map:
        return {
            "coupling_density": 0.0,
            "max_degree": 0,
            "avg_degree": 0.0,
            "connectivity_ratio": 0.0,
            "diameter": 0,
            "clustering_coefficient": 0.0
        }
    
    # ì¸ì ‘ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    adjacency = {i: set() for i in range(n_qubits)}
    for edge in coupling_map:
        if len(edge) >= 2:
            a, b = edge[0], edge[1]
            if a < n_qubits and b < n_qubits:
                adjacency[a].add(b)
                adjacency[b].add(a)
    
    # 1. ì»¤í”Œë§ ë°€ë„ (ì‹¤ì œ ì—°ê²° / ìµœëŒ€ ê°€ëŠ¥ ì—°ê²°)
    total_edges = len(coupling_map)
    max_edges = n_qubits * (n_qubits - 1) // 2
    coupling_density = total_edges / max_edges if max_edges > 0 else 0
    
    # 2. ì°¨ìˆ˜ í†µê³„
    degrees = [len(neighbors) for neighbors in adjacency.values()]
    max_degree = max(degrees) if degrees else 0
    avg_degree = np.mean(degrees) if degrees else 0
    
    # 3. ì—°ê²°ì„± ë¹„ìœ¨ (ì—°ê²°ëœ íë¹— / ì „ì²´ íë¹—)
    connected_qubits = sum(1 for d in degrees if d > 0)
    connectivity_ratio = connected_qubits / n_qubits if n_qubits > 0 else 0
    
    # 4. ê·¸ë˜í”„ ì§€ë¦„ (ìµœë‹¨ ê²½ë¡œì˜ ìµœëŒ€ê°’) - ê°„ë‹¨í•œ BFS
    diameter = calculate_graph_diameter(adjacency, n_qubits)
    
    # 5. í´ëŸ¬ìŠ¤í„°ë§ ê³„ìˆ˜ (ì‚¼ê°í˜• í˜•ì„± ì •ë„)
    clustering_coefficient = calculate_clustering_coefficient(adjacency)
    
    return {
        "coupling_density": coupling_density,
        "max_degree": max_degree,
        "avg_degree": avg_degree,
        "connectivity_ratio": connectivity_ratio,
        "diameter": diameter,
        "clustering_coefficient": clustering_coefficient
    }

def calculate_graph_diameter(adjacency, n_qubits):
    """ê·¸ë˜í”„ì˜ ì§€ë¦„ ê³„ì‚° (BFS ê¸°ë°˜)"""
    from collections import deque
    
    max_distance = 0
    
    for start in range(n_qubits):
        if not adjacency[start]:  # ì—°ê²°ë˜ì§€ ì•Šì€ ë…¸ë“œëŠ” ê±´ë„ˆëœ€
            continue
            
        # BFSë¡œ ìµœë‹¨ ê±°ë¦¬ ê³„ì‚°
        distances = {start: 0}
        queue = deque([start])
        
        while queue:
            current = queue.popleft()
            
            for neighbor in adjacency[current]:
                if neighbor not in distances:
                    distances[neighbor] = distances[current] + 1
                    queue.append(neighbor)
                    max_distance = max(max_distance, distances[neighbor])
    
    return max_distance

def calculate_clustering_coefficient(adjacency):
    """í´ëŸ¬ìŠ¤í„°ë§ ê³„ìˆ˜ ê³„ì‚°"""
    total_coefficient = 0
    valid_nodes = 0
    
    for node, neighbors in adjacency.items():
        if len(neighbors) < 2:
            continue
            
        # ì´ì›ƒ ë…¸ë“œë“¤ ê°„ì˜ ì—°ê²° ìˆ˜ ê³„ì‚°
        neighbor_list = list(neighbors)
        possible_edges = len(neighbor_list) * (len(neighbor_list) - 1) // 2
        actual_edges = 0
        
        for i in range(len(neighbor_list)):
            for j in range(i + 1, len(neighbor_list)):
                if neighbor_list[j] in adjacency[neighbor_list[i]]:
                    actual_edges += 1
        
        if possible_edges > 0:
            total_coefficient += actual_edges / possible_edges
            valid_nodes += 1
    
    return total_coefficient / valid_nodes if valid_nodes > 0 else 0

def create_circuit_embedding(circuit_sequence, max_length=100):
    """íšŒë¡œ ì‹œí€€ìŠ¤ë¥¼ íŠ¸ëœìŠ¤í¬ë¨¸ ì…ë ¥ìš© ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ - ê°œì„ ëœ ë²„ì „"""
    # ê²Œì´íŠ¸ íƒ€ì…ì„ ìˆ«ìë¡œ ë§¤í•‘
    gate_to_id = {
        "H": 1, "X": 2, "Y": 3, "Z": 4, "S": 5, "T": 6, "RZ": 7, "CNOT": 8,
        "PAD": 0  # íŒ¨ë”©ìš©
    }
    
    # ì‹œí€€ìŠ¤ë¥¼ ê³ ì • ê¸¸ì´ë¡œ ë³€í™˜
    gate_sequence = []
    qubit_sequence = []
    param_sequence = []
    gate_type_sequence = []  # ë‹¨ì¼/ì´ì¤‘ íë¹— ê²Œì´íŠ¸ êµ¬ë¶„
    
    for gate_info in circuit_sequence[:max_length]:
        gate_id = gate_to_id.get(gate_info["gate"], 0)
        gate_sequence.append(gate_id)
        
        # íë¹— ìœ„ì¹˜ ì •ë³´ (ì²« ë²ˆì§¸ íë¹—ë§Œ ì‚¬ìš©, íŒ¨ë”©ì€ -1)
        if gate_info["qubits"]:
            qubit_sequence.append(gate_info["qubits"][0])
        else:
            qubit_sequence.append(-1)
        
        # íŒŒë¼ë¯¸í„° ê°’ (ì—†ìœ¼ë©´ 0)
        if gate_info["params"]:
            param_sequence.append(gate_info["params"][0])
        else:
            param_sequence.append(0.0)
        
        # ê²Œì´íŠ¸ íƒ€ì… (1: ë‹¨ì¼ íë¹—, 2: ì´ì¤‘ íë¹—)
        if gate_info["gate"] == "CNOT":
            gate_type_sequence.append(2)
        else:
            gate_type_sequence.append(1)
    
    # íŒ¨ë”©
    while len(gate_sequence) < max_length:
        gate_sequence.append(0)
        qubit_sequence.append(-1)
        param_sequence.append(0.0)
        gate_type_sequence.append(0)
    
    # ì¶”ê°€ ì‹œí€€ìŠ¤ íŠ¹ì„± ê³„ì‚°
    sequence_features = {
        "sequence_length": min(len(circuit_sequence), max_length),
        "unique_gates_in_sequence": len(set(gate_sequence[:min(len(circuit_sequence), max_length)])),
        "param_gate_ratio": sum(1 for p in param_sequence if p != 0) / max_length,
        "two_qubit_gate_ratio": sum(1 for t in gate_type_sequence if t == 2) / max_length
    }
    
    return {
        "gate_sequence": gate_sequence,
        "qubit_sequence": qubit_sequence,
        "param_sequence": param_sequence,
        "gate_type_sequence": gate_type_sequence,
        "sequence_features": sequence_features
    }

def calculate_measurement_statistics(counts, n_qubits):
    """ì‹¤ì œ ì¸¡ì • ê²°ê³¼ì—ì„œë§Œ ë‚˜ì˜¤ëŠ” í†µê³„ì  íŠ¹ì„±"""
    if not counts:
        return {}
    
    total_counts = sum(counts.values())
    probabilities = np.array([count / total_counts for count in counts.values()])
    
    # 1. ì‹¤ì œ ì¸¡ì • ë¶„í¬ íŠ¹ì„±
    entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))
    
    # 2. ì‹¤ì œ ìƒíƒœ ë¶„í¬
    zero_state = '0' * n_qubits
    zero_prob = counts.get(zero_state, 0) / total_counts
    
    # 3. ì¸¡ì • ì§‘ì¤‘ë„ (ê°€ì¥ ë§ì´ ì¸¡ì •ëœ ìƒíƒœì˜ ë¹„ìœ¨)
    max_count = max(counts.values())
    concentration = max_count / total_counts
    
    # 4. ìœ íš¨ ìƒíƒœ ìˆ˜ (ì‹¤ì œë¡œ ì¸¡ì •ëœ ìƒíƒœ ìˆ˜)
    measured_states = len(counts)
    
    # 5. ë¶„ì‚° ë° í‘œì¤€í¸ì°¨
    count_values = list(counts.values())
    measurement_variance = np.var(count_values)
    measurement_std = np.std(count_values)
    
    # 6. ìƒìœ„ ìƒíƒœë“¤ì˜ ëˆ„ì  í™•ë¥ 
    sorted_probs = sorted(probabilities, reverse=True)
    top_1_prob = sorted_probs[0] if len(sorted_probs) > 0 else 0
    top_5_prob = sum(sorted_probs[:5]) if len(sorted_probs) >= 5 else sum(sorted_probs)
    top_10_prob = sum(sorted_probs[:10]) if len(sorted_probs) >= 10 else sum(sorted_probs)
    
    return {
        "entropy": entropy,
        "zero_state_probability": zero_prob,
        "concentration": concentration,
        "measured_states": measured_states,
        "measurement_variance": measurement_variance,
        "measurement_std": measurement_std,
        "top_1_probability": top_1_prob,
        "top_5_probability": top_5_prob,
        "top_10_probability": top_10_prob,
        "total_measurements": total_counts
    }

def calculate_robust_fidelity_mega(counts, n_qubits, total_counts):
    """
    ë©”ê°€ì¡ìš© Robust Fidelity ê³„ì‚° (ë…¸ì´ì¦ˆ í—ˆìš©)
    
    Args:
        counts (dict): ì¸¡ì • ê²°ê³¼ ì¹´ìš´íŠ¸ {ë¹„íŠ¸ì—´: ì¹´ìš´íŠ¸}
        n_qubits (int): íë¹— ìˆ˜
        total_counts (int): ì´ ì¸¡ì • íšŸìˆ˜
        
    Returns:
        float: Robust Fidelity (0~1 ì‚¬ì´)
    """
    if total_counts == 0:
        return 0.0
    
    # ëª©í‘œ ìƒíƒœ (ëª¨ë“  ë¹„íŠ¸ê°€ 0)
    target_state = '0' * n_qubits
    
    # í—ˆìš© ì˜¤ë¥˜ ë¹„íŠ¸ ìˆ˜
    error_threshold = get_error_threshold_mega(n_qubits)
    
    # í—ˆìš© ë²”ìœ„ ë‚´ì˜ ëª¨ë“  ì¸¡ì • ì¹´ìš´íŠ¸ í•©ì‚°
    robust_count = 0
    
    for measured_state, count in counts.items():
        # ì¸¡ì •ëœ ìƒíƒœì™€ ëª©í‘œ ìƒíƒœ ê°„ì˜ í•´ë° ê±°ë¦¬ ê³„ì‚°
        distance = hamming_distance_mega(measured_state, target_state)
        
        # í—ˆìš© ë²”ìœ„ ë‚´ì´ë©´ ì¹´ìš´íŠ¸ì— í¬í•¨
        if distance <= error_threshold:
            robust_count += count
    
    # Robust Fidelity ê³„ì‚°
    robust_fidelity = robust_count / total_counts
    
    return robust_fidelity

def get_error_threshold_mega(n_qubits):
    """
    ë©”ê°€ì¡ìš© íë¹— ìˆ˜ì— ë”°ë¥¸ í—ˆìš© ì˜¤ë¥˜ ë¹„íŠ¸ ìˆ˜ ê³„ì‚°
    
    Args:
        n_qubits (int): íë¹— ìˆ˜
        
    Returns:
        int: í—ˆìš© ì˜¤ë¥˜ ë¹„íŠ¸ ìˆ˜
    """
    if n_qubits <= 10:
        return 1  # 10íë¹— ì´í•˜ëŠ” 1ê°œ ì˜¤ë¥˜ë§Œ í—ˆìš©
    else:
        return max(1, int(n_qubits * 0.1))  # 10% ì´ë‚´ ì˜¤ë¥˜ í—ˆìš©

def hamming_distance_mega(state1, state2):
    """
    ë©”ê°€ì¡ìš© ë‘ ë¹„íŠ¸ ë¬¸ìì—´ ê°„ì˜ í•´ë° ê±°ë¦¬ ê³„ì‚°
    
    Args:
        state1 (str): ì²« ë²ˆì§¸ ë¹„íŠ¸ ë¬¸ìì—´
        state2 (str): ë‘ ë²ˆì§¸ ë¹„íŠ¸ ë¬¸ìì—´
        
    Returns:
        int: í•´ë° ê±°ë¦¬ (ë‹¤ë¥¸ ë¹„íŠ¸ ìˆ˜)
    """
    if len(state1) != len(state2):
        return float('inf')  # ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ë¬´í•œëŒ€ ê±°ë¦¬
    
    return sum(c1 != c2 for c1, c2 in zip(state1, state2))

def calculate_optimal_shots_and_batching(total_circuits, target_total_shots=8000000, max_executions=10000000):
    """
    Config ì„¤ì • ê¸°ë°˜ ìµœì  ìƒ· ìˆ˜ ë° ë°°ì¹˜ ë¶„í•  ê³„ì‚°
    
    Args:
        total_circuits (int): ì´ íšŒë¡œ ìˆ˜
        target_total_shots (int): ëª©í‘œ ì´ ìƒ· ìˆ˜ (ì°¸ê³ ìš©)
        max_executions (int): IBM ì œí•œ ìµœëŒ€ ì‹¤í–‰ ìˆ˜
        
    Returns:
        dict: ë°°ì¹˜ ë¶„í•  ì •ë³´
    """
    from config import config
    
    print("\nğŸ¯ Config ê¸°ë°˜ ìµœì  ìƒ· ìˆ˜ ë° ë°°ì¹˜ ë¶„í•  ê³„ì‚°")
    
    # íšŒë¡œë³„ ì‹¤ì œ í•„ìš” ìƒ· ìˆ˜ ê³„ì‚° (config ì„¤ì • ê¸°ë°˜)
    # ì˜ˆì‹œ íšŒë¡œë“¤ì˜ íë¹— ìˆ˜ ë¶„í¬ (5, 7, 10 íë¹—)
    circuit_shot_requirements = []
    
    # ê° íšŒë¡œ ì„¤ì •ë³„ ìƒ· ìˆ˜ ê³„ì‚°
    qubit_configs = [5, 7, 10]  # ì‹¤ì œ ìƒì„±ë˜ëŠ” íšŒë¡œì˜ íë¹— ìˆ˜
    circuits_per_config = total_circuits // (3 * 3 * 3)  # 3Ã—3Ã—3 = 27ê°œ ì„¤ì •
    
    for n_qubits in qubit_configs:
        # í”¼ë¸ë¦¬í‹° ì¸¡ì •ìš© ìƒ· ìˆ˜ (config ê¸°ë°˜)
        fidelity_shots = config.get_ibm_shots(n_qubits)
        
        # í‘œí˜„ë ¥ ì¸¡ì •ìš© ìƒ· ìˆ˜ (config ê¸°ë°˜)
        expressibility_samples = config.ibm_backend.expressibility_samples  # 32
        expressibility_shots_per_sample = config.ibm_backend.expressibility_shots  # 64
        expressibility_total_shots = expressibility_samples * expressibility_shots_per_sample  # 32 Ã— 64 = 2,048
        
        # íšŒë¡œë‹¹ ì´ ìƒ· ìˆ˜
        shots_per_circuit = fidelity_shots + expressibility_total_shots
        
        print(f"  {n_qubits}íë¹— íšŒë¡œ:")
        print(f"    í”¼ë¸ë¦¬í‹° ì¸¡ì •: {fidelity_shots} ìƒ·")
        print(f"    í‘œí˜„ë ¥ ì¸¡ì •: {expressibility_samples} ìƒ˜í”Œ Ã— {expressibility_shots_per_sample} ìƒ· = {expressibility_total_shots} ìƒ·")
        print(f"    íšŒë¡œë‹¹ ì´ ìƒ· ìˆ˜: {shots_per_circuit:,} ìƒ·")
        
        # í•´ë‹¹ íë¹— ìˆ˜ì˜ íšŒë¡œ ìˆ˜ë§Œí¼ ì¶”ê°€
        num_circuits_this_config = circuits_per_config * 9  # 3ê°œ ê¹Šì´ Ã— 3ê°œ ë¹„ìœ¨
        for _ in range(num_circuits_this_config):
            circuit_shot_requirements.append(shots_per_circuit)
    
    # ì „ì²´ í•„ìš” ìƒ· ìˆ˜ ê³„ì‚°
    total_required_shots = sum(circuit_shot_requirements)
    
    print(f"\nğŸ“Š ì „ì²´ ìƒ· ìˆ˜ ìš”êµ¬ì‚¬í•­:")
    print(f"  ì´ íšŒë¡œ ìˆ˜: {total_circuits:,}")
    print(f"  ì´ í•„ìš” ìƒ· ìˆ˜: {total_required_shots:,}")
    print(f"  ëª©í‘œ ìƒ· ìˆ˜: {target_total_shots:,}")
    print(f"  IBM ì œí•œ: {max_executions:,} ì‹¤í–‰")
    
    # ë°°ì¹˜ ë¶„í•  ê³„ì‚° (IBM ì œí•œ ë‚´ì—ì„œ)
    batches = []
    current_batch_shots = 0
    current_batch_circuits = []
    
    for i, shots_needed in enumerate(circuit_shot_requirements):
        # í˜„ì¬ ë°°ì¹˜ì— ì¶”ê°€í–ˆì„ ë•Œ IBM ì œí•œì„ ì´ˆê³¼í•˜ëŠ”ì§€ í™•ì¸
        if current_batch_shots + shots_needed > max_executions:
            # í˜„ì¬ ë°°ì¹˜ ì™„ë£Œí•˜ê³  ìƒˆ ë°°ì¹˜ ì‹œì‘
            if current_batch_circuits:
                batches.append({
                    "circuits": current_batch_circuits.copy(),
                    "total_shots": current_batch_shots,
                    "circuit_count": len(current_batch_circuits)
                })
                print(f"  ë°°ì¹˜ {len(batches)}: {len(current_batch_circuits)}ê°œ íšŒë¡œ, {current_batch_shots:,} ìƒ·")
            
            # ìƒˆ ë°°ì¹˜ ì‹œì‘
            current_batch_circuits = [i]
            current_batch_shots = shots_needed
        else:
            # í˜„ì¬ ë°°ì¹˜ì— ì¶”ê°€
            current_batch_circuits.append(i)
            current_batch_shots += shots_needed
    
    # ë§ˆì§€ë§‰ ë°°ì¹˜ ì¶”ê°€
    if current_batch_circuits:
        batches.append({
            "circuits": current_batch_circuits.copy(),
            "total_shots": current_batch_shots,
            "circuit_count": len(current_batch_circuits)
        })
        print(f"  ë°°ì¹˜ {len(batches)}: {len(current_batch_circuits)}ê°œ íšŒë¡œ, {current_batch_shots:,} ìƒ·")
    
    # ë°°ì¹˜ ì •ë³´ ìš”ì•½
    total_batches = len(batches)
    circuits_per_batch = [batch["circuit_count"] for batch in batches]
    executions_per_batch = [batch["total_shots"] for batch in batches]
    
    print(f"\nâœ… ë°°ì¹˜ ë¶„í•  ì™„ë£Œ:")
    print(f"  ì´ ë°°ì¹˜ ìˆ˜: {total_batches}")
    print(f"  ë°°ì¹˜ë³„ íšŒë¡œ ìˆ˜: {circuits_per_batch}")
    print(f"  ë°°ì¹˜ë³„ ì‹¤í–‰ ìˆ˜: {[f'{shots:,}' for shots in executions_per_batch]}")
    print(f"  ì´ ì‹¤í–‰ ìˆ˜: {sum(executions_per_batch):,}")
    print(f"  IBM ì œí•œ ì¤€ìˆ˜: {'âœ…' if all(shots <= max_executions for shots in executions_per_batch) else 'âŒ'}")
    
    # ìƒ· ìˆ˜ ì ì ˆì„± ê²€ì¦
    print(f"\nğŸ” ìƒ· ìˆ˜ ì ì ˆì„± ê²€ì¦:")
    avg_shots_per_circuit = total_required_shots / total_circuits
    print(f"   íšŒë¡œë‹¹ í‰ê·  ìƒ· ìˆ˜: {avg_shots_per_circuit:,.0f}")
    
    # í”¼ë¸ë¦¬í‹° ì¸¡ì • ì‹ ë¢°ì„± (ìµœì†Œ 1024ìƒ· ê¶Œì¥)
    min_fidelity_shots = min([config.get_ibm_shots(n) for n in qubit_configs])
    fidelity_adequate = min_fidelity_shots >= 1024
    print(f"   í”¼ë¸ë¦¬í‹° ì¸¡ì • ì‹ ë¢°ì„±: {'âœ… ì¶©ë¶„' if fidelity_adequate else 'âš ï¸ ë¶€ì¡±'} ({min_fidelity_shots} â‰¥ 1024)")
    
    # í‘œí˜„ë ¥ ê³„ì‚° ì •í™•ì„± (ìµœì†Œ 512ìƒ· ê¶Œì¥)
    expressibility_shots = config.ibm_backend.expressibility_samples * config.ibm_backend.expressibility_shots
    expressibility_adequate = expressibility_shots >= 512
    print(f"   í‘œí˜„ë ¥ ê³„ì‚° ì •í™•ì„±: {'âœ… ì ì ˆ' if expressibility_adequate else 'âš ï¸ ë¶€ì¡±'} ({expressibility_shots} â‰¥ 512)")
    
    # í†µê³„ì  ìœ ì˜ì„± (ìµœì†Œ 256ìƒ· ê¶Œì¥)
    statistical_adequate = avg_shots_per_circuit >= 256
    print(f"   í†µê³„ì  ìœ ì˜ì„±: {'âœ… ë³´ì¥' if statistical_adequate else 'âš ï¸ ë¶€ì¡±'} ({avg_shots_per_circuit:.0f} â‰¥ 256)")
    
    return {
        "num_batches": total_batches,
        "circuits_per_batch": circuits_per_batch,
        "executions_per_batch": executions_per_batch,
        "total_executions": sum(executions_per_batch),
        "circuit_shot_requirements": circuit_shot_requirements,
        "batches": batches,
        "data_integrity": "ì™„ì „ ë³´ì¥ (Config ê¸°ë°˜ ì ì • ìƒ· ìˆ˜)",
        "shots_adequacy": {
            "fidelity_adequate": fidelity_adequate,
            "expressibility_adequate": expressibility_adequate,
            "statistical_adequate": statistical_adequate
        }
    }

def setup_directories():
    """í”„ë¡œê·¸ë¨ ì‹¤í–‰ì— í•„ìš”í•œ ëª¨ë“  ë””ë ‰í† ë¦¬ ìƒì„±"""
    print("ğŸ“ í•„ìš”í•œ ë””ë ‰í† ë¦¬ë“¤ì„ ìƒì„± ì¤‘...")
    
    # ìƒì„±í•  ë””ë ‰í† ë¦¬ ëª©ë¡
    directories = [
        "grid_circuits",                    # ë©”ì¸ ë””ë ‰í† ë¦¬
        "grid_circuits/mega_results",       # ë©”ê°€ì¡ ê²°ê³¼ ì €ì¥
        "grid_circuits/training_data",      # AI í›ˆë ¨ ë°ì´í„°
        "grid_circuits/analysis",           # ë¶„ì„ ê²°ê³¼
        "grid_circuits/logs",               # ë¡œê·¸ íŒŒì¼
        "grid_circuits/temp",               # ì„ì‹œ íŒŒì¼
        "grid_circuits/backup",             # ë°±ì—… íŒŒì¼
        "models",                           # í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥
        "plots",                            # ì‹œê°í™” ê²°ê³¼
        "reports"                           # ë³´ê³ ì„œ
    ]
    
    created_dirs = []
    existing_dirs = []
    
    for directory in directories:
        try:
            if not os.path.exists(directory):
                os.makedirs(directory, exist_ok=True)
                created_dirs.append(directory)
                print(f"  âœ… ìƒì„±ë¨: {directory}")
            else:
                existing_dirs.append(directory)
                print(f"  ğŸ“‚ ì´ë¯¸ ì¡´ì¬: {directory}")
        except Exception as e:
            print(f"  âŒ ìƒì„± ì‹¤íŒ¨: {directory} - {str(e)}")
    
    print(f"\nğŸ“Š ë””ë ‰í† ë¦¬ ì„¤ì • ì™„ë£Œ:")
    print(f"  ìƒˆë¡œ ìƒì„±: {len(created_dirs)}ê°œ")
    print(f"  ê¸°ì¡´ ì¡´ì¬: {len(existing_dirs)}ê°œ")
    
    # ê¶Œí•œ í™•ì¸
    test_file_path = os.path.join("grid_circuits/mega_results", "test_write.tmp")
    try:
        with open(test_file_path, 'w') as f:
            f.write("test")
        os.remove(test_file_path)
        print(f"  âœ… ì“°ê¸° ê¶Œí•œ í™•ì¸ ì™„ë£Œ")
    except Exception as e:
        print(f"  âš ï¸ ì“°ê¸° ê¶Œí•œ ë¬¸ì œ: {str(e)}")
    
    return True

def run_mega_job_generator():
    """ë©”ì¸ 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜ (1800ê°œ íšŒë¡œ)"""
    
    start_time = time.time()
    
    try:
        # 0ï¸âƒ£ ë””ë ‰í† ë¦¬ ì„¤ì •
        print("0ï¸âƒ£ í”„ë¡œê·¸ë¨ í™˜ê²½ ì„¤ì •")
        setup_directories()
        
        # IBM ë°±ì—”ë“œ ì´ˆê¸°í™”
        print("\n1ï¸âƒ£ IBM Quantum ë°±ì—”ë“œ ì´ˆê¸°í™”")
        ibm_token = os.environ.get('IBM_QUANTUM_TOKEN')
        if not ibm_token:
            print("âŒ IBM_QUANTUM_TOKEN í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        ibm_backend = IBMQuantumBackend(ibm_token=ibm_token)
        if not ibm_backend or not ibm_backend.backend:
            print("âŒ IBM ë°±ì—”ë“œ ì—°ê²° ì‹¤íŒ¨")
            return
        
        print(f"âœ… {ibm_backend.backend.name} ì—°ê²° ì„±ê³µ")
        
        # 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ í…ŒìŠ¤íŠ¸ìš© íšŒë¡œ ìƒì„±
        print("\n2ï¸âƒ£ 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ í…ŒìŠ¤íŠ¸ìš© 1800ê°œ íšŒë¡œ ìƒì„±")
        all_circuits = generate_all_circuits()
        
        # Qiskit íšŒë¡œë¡œ ë³€í™˜
        print("\n3ï¸âƒ£ Qiskit íšŒë¡œ ë³€í™˜ ë° ê²€ì¦")
        qiskit_circuits = []
        conversion_errors = 0
        
        print(f"1800ê°œ íšŒë¡œë¥¼ Qiskit í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì¤‘...")
        for i, circuit_info in enumerate(all_circuits):
            try:
                # íšŒë¡œ ì •ë³´ì—ì„œ ì§ì ‘ ì‚¬ìš© (ì´ë¯¸ circuit_info í˜•íƒœ)
                qiskit_circuits.append(circuit_info)
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥ (100ê°œë§ˆë‹¤)
                if (i + 1) % 100 == 0:
                    print(f"  ë³€í™˜ ì§„í–‰ë¥ : {(i+1)/len(all_circuits)*100:.1f}% ({i+1}/{len(all_circuits)})")
                    
            except Exception as e:
                print(f"âš ï¸ íšŒë¡œ {i} ë³€í™˜ ì˜¤ë¥˜: {str(e)}")
                conversion_errors += 1
        
        print(f"âœ… {len(qiskit_circuits)}ê°œ íšŒë¡œ ë³€í™˜ ì™„ë£Œ (ì˜¤ë¥˜: {conversion_errors}ê°œ)")
        
        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ IBM ë°±ì—”ë“œ ì‹¤í–‰
        print("\n4ï¸âƒ£ IBM ë°±ì—”ë“œì—ì„œ ìµœì í™”ëœ ë°°ì¹˜ ì‹¤í–‰")
        
        # 800ë§Œ ìƒ· ë‚´ì™¸ë¡œ ìµœì í™”ëœ ë°°ì¹˜ ê³„ì‚°
        target_total_shots = 8000000  # 800ë§Œ ìƒ· ëª©í‘œ
        
        print(f"ëª©í‘œ ì´ ìƒ· ìˆ˜: {target_total_shots:,}")
        
        # ìµœì  ìƒ· ìˆ˜ ë° ë°°ì¹˜ ë¶„í•  ê³„ì‚°
        batch_info = calculate_optimal_shots_and_batching(
            total_circuits=len(qiskit_circuits),
            target_total_shots=target_total_shots,
            max_executions=10000000  # IBM ì œí•œ: 1000ë§Œ ì‹¤í–‰
        )
        
        # ê³„ì‚°ëœ ìµœì  ìƒ· ìˆ˜ ì‚¬ìš©
        print(f"\nğŸ¯ Config ê¸°ë°˜ ì‹¤í–‰ ê³„íš:")
        print(f"   ì´ ë°°ì¹˜ ìˆ˜: {batch_info['num_batches']}")
        print(f"   ì´ ì‹¤í–‰ ìˆ˜: {batch_info['total_executions']:,}")
        print(f"   ë°ì´í„° ë¬´ê²°ì„±: {batch_info['data_integrity']}")
        
        # ë°°ì¹˜ë³„ ì‹¤í–‰
        all_results = []
        successful_executions = 0
        failed_executions = 0
        
        for batch_idx in range(batch_info["num_batches"]):
            batch_data = batch_info["batches"][batch_idx]
            batch_circuit_indices = batch_data["circuits"]
            batch_total_shots = batch_data["total_shots"]
            batch_circuit_count = batch_data["circuit_count"]
            
            print(f"\nğŸ“¦ ë°°ì¹˜ {batch_idx + 1}/{batch_info['num_batches']} ì‹¤í–‰ ì¤‘...")
            print(f"   íšŒë¡œ ìˆ˜: {batch_circuit_count:,}")
            print(f"   ë°°ì¹˜ ì´ ì‹¤í–‰ ìˆ˜: {batch_total_shots:,}")
            
            # í˜„ì¬ ë°°ì¹˜ì˜ íšŒë¡œ ì„ íƒ
            batch_circuits = [qiskit_circuits[i] for i in batch_circuit_indices]
            batch_metadata = [all_circuits[i] for i in batch_circuit_indices]
            
            print(f"   íšŒë¡œ ì¸ë±ìŠ¤: {batch_circuit_indices[:5]}{'...' if len(batch_circuit_indices) > 5 else ''}")
            
            # ë°°ì¹˜ ì‹¤í–‰ (ê° íšŒë¡œë§ˆë‹¤ config ê¸°ë°˜ ìƒ· ìˆ˜ ì‚¬ìš©)
            try:
                # ë°°ì¹˜ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì‘ì—…ìœ¼ë¡œ ì‹¤í–‰
                print(f"   ğŸš€ ë°°ì¹˜ {batch_idx + 1} ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì‘ì—…ìœ¼ë¡œ ì‹¤í–‰ ì¤‘...")
                
                batch_results = run_mega_job(
                    batch_circuits, 
                    batch_metadata, 
                    ibm_backend, 
                    shots=128,  # ê¸°ë³¸ê°’ ì œê³µ (circuit_shot_requirementsê°€ ìš°ì„ )
                    circuit_shot_requirements=[batch_info["circuit_shot_requirements"][i] for i in batch_circuit_indices]
                )
                
                if batch_results:
                    all_results.extend(batch_results)
                    successful_executions += len(batch_results)
                    print(f"   âœ… ë°°ì¹˜ {batch_idx + 1} ì„±ê³µ: {len(batch_results)}ê°œ íšŒë¡œ ì™„ë£Œ")
                    
                    # ë°°ì¹˜ ì„±ëŠ¥ ìš”ì•½
                    batch_fidelities = [r["execution_result"].get("zero_state_probability", 0) for r in batch_results]
                    batch_robust_fidelities = [r["execution_result"].get("robust_fidelity", 0) for r in batch_results]
                    batch_error_rates = [r["execution_result"].get("error_rates", {}).get("total_error_rate", 0) for r in batch_results]
                    
                    print(f"   ğŸ“Š ë°°ì¹˜ ì„±ëŠ¥ ìš”ì•½:")
                    print(f"      í‰ê·  í”¼ë¸ë¦¬í‹°: {np.mean(batch_fidelities):.6f}")
                    print(f"      í‰ê·  Robust í”¼ë¸ë¦¬í‹°: {np.mean(batch_robust_fidelities):.6f}")
                    print(f"      í‰ê·  ì˜¤ë¥˜ìœ¨: {np.mean(batch_error_rates):.6f}")
                else:
                    failed_executions += batch_circuit_count
                    print(f"   âŒ ë°°ì¹˜ {batch_idx + 1} ì‹¤íŒ¨")
                
                # ë°°ì¹˜ ê²°ê³¼ ì €ì¥ (ì¤‘ê°„ ì €ì¥ìœ¼ë¡œ ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥)
                if batch_results:
                    batch_filename = f"batch_{batch_idx + 1}_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                    save_batch_results(batch_results, batch_filename)
                    print(f"   ğŸ’¾ ë°°ì¹˜ ê²°ê³¼ ì €ì¥: {batch_filename}")
                    
                    # ë§¤ 100ê°œ íšŒë¡œë§ˆë‹¤ ì¤‘ê°„ í†µí•© ê²°ê³¼ ì €ì¥
                    if len(all_results) % 100 == 0 and len(all_results) > 0:
                        interim_filename = f"interim_results_{len(all_results)}_circuits_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                        save_final_results(all_results, interim_filename)
                        print(f"   ğŸ“Š ì¤‘ê°„ í†µí•© ê²°ê³¼ ì €ì¥: {interim_filename} ({len(all_results)}ê°œ íšŒë¡œ)")
                        
                        # ì¤‘ê°„ ìš”ì•½ í†µê³„ë„ ì €ì¥
                        interim_summary = generate_summary_statistics(all_results)
                        interim_summary_filename = f"interim_summary_{len(all_results)}_circuits_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                        
                        save_dir = "grid_circuits/mega_results"
                        os.makedirs(save_dir, exist_ok=True)
                        interim_summary_filepath = os.path.join(save_dir, interim_summary_filename)
                        
                        with open(interim_summary_filepath, 'w', encoding='utf-8') as f:
                            json.dump(interim_summary, f, indent=2, default=str, ensure_ascii=False)
                        print(f"   ğŸ“ˆ ì¤‘ê°„ ìš”ì•½ í†µê³„ ì €ì¥: {interim_summary_filepath}")
                
            except Exception as e:
                print(f"   âŒ ë°°ì¹˜ {batch_idx + 1} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                failed_executions += batch_circuit_count
                continue
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            total_processed = successful_executions + failed_executions
            progress = total_processed / len(qiskit_circuits) * 100
            print(f"   ğŸ“Š ì „ì²´ ì§„í–‰ë¥ : {progress:.1f}% ({total_processed}/{len(qiskit_circuits)})")
            
            # ì‹¤ì œ ì‚¬ìš©ëœ ìƒ· ìˆ˜ ê³„ì‚°
            actual_shots_used = sum([batch_info["circuit_shot_requirements"][i] for i in range(successful_executions)])
            print(f"   ğŸ¯ ëˆ„ì  ìƒ· ì‚¬ìš©ëŸ‰: {actual_shots_used:,}")
            
            # ë°°ì¹˜ ê°„ ëŒ€ê¸° ì‹œê°„ (ë°±ì—”ë“œ ë¶€í•˜ ë¶„ì‚°)
            if batch_idx < batch_info["num_batches"] - 1:
                wait_time = 30  # 30ì´ˆ ëŒ€ê¸°
                print(f"   â³ ë‹¤ìŒ ë°°ì¹˜ê¹Œì§€ {wait_time}ì´ˆ ëŒ€ê¸°...")
                time.sleep(wait_time)
        
        print(f"\nâœ… ì „ì²´ ì‹¤í–‰ ì™„ë£Œ!")
        print(f"   ì„±ê³µí•œ íšŒë¡œ: {successful_executions}/{len(qiskit_circuits)}")
        print(f"   ì‹¤íŒ¨í•œ íšŒë¡œ: {failed_executions}")
        print(f"   ì„±ê³µë¥ : {successful_executions/len(qiskit_circuits)*100:.1f}%")
        
        # ì‹¤ì œ ì‚¬ìš©ëœ ì´ ìƒ· ìˆ˜ ê³„ì‚°
        actual_total_shots = sum([batch_info["circuit_shot_requirements"][i] for i in range(successful_executions)])
        print(f"   ì‹¤ì œ ì‚¬ìš©ëœ ì´ ìƒ· ìˆ˜: {actual_total_shots:,}")
        print(f"   ëª©í‘œ ëŒ€ë¹„ ìƒ· ì‚¬ìš©ë¥ : {(actual_total_shots)/target_total_shots*100:.1f}%")
        
        if not all_results:
            print("âš ï¸ ì‹¤í–‰ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 5ï¸âƒ£ ê²°ê³¼ ë¶„ì„ ë° ì €ì¥
        print("\n5ï¸âƒ£ ê²°ê³¼ ë¶„ì„ ë° ì €ì¥")
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        final_filename = f"mega_job_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        save_final_results(all_results, final_filename)
        print(f"ìµœì¢… ê²°ê³¼ ì €ì¥ë¨: {final_filename}")
        
        # 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ ë¶„ì„
        analyze_two_qubit_ratio_results(all_results)
        
        # ìš”ì•½ í†µê³„ ìƒì„± (ì‹¤ì œ ìƒ· ìˆ˜ ì •ë³´ í¬í•¨)
        summary_stats = generate_summary_statistics(all_results)
        
        # ì‹¤ì œ ì‚¬ìš©ëœ ì´ ìƒ· ìˆ˜ ê³„ì‚°
        actual_total_shots_final = sum([batch_info["circuit_shot_requirements"][i] for i in range(successful_executions)])
        
        summary_stats["execution_info"] = {
            "target_total_shots": target_total_shots,
            "actual_total_shots": actual_total_shots_final,
            "shots_efficiency": actual_total_shots_final / target_total_shots,
            "data_integrity": batch_info["data_integrity"],
            "batch_count": batch_info["num_batches"],
            "config_based_shots": True,
            "shots_adequacy": batch_info["shots_adequacy"]
        }
        
        # ìš”ì•½ í†µê³„ ì €ì¥
        summary_filename = f"summary_statistics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
        save_dir = "grid_circuits/mega_results"
        os.makedirs(save_dir, exist_ok=True)
        summary_filepath = os.path.join(save_dir, summary_filename)
        
        with open(summary_filepath, 'w', encoding='utf-8') as f:
            json.dump(summary_stats, f, indent=2, default=str, ensure_ascii=False)
        print(f"âœ… ìš”ì•½ í†µê³„ ì €ì¥ë¨: {summary_filepath}")
        
        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        total_execution_time = time.time() - start_time
        
        print(f"\nğŸ‰ Config ê¸°ë°˜ ë©”ê°€ì¡ ì™„ë£Œ!")
        print(f"   ì´ ì‹¤í–‰ ì‹œê°„: {total_execution_time/3600:.1f}ì‹œê°„")
        print(f"   ëª©í‘œ ìƒ· ìˆ˜: {target_total_shots:,}")
        print(f"   ì‹¤ì œ ì‚¬ìš© ìƒ· ìˆ˜: {actual_total_shots_final:,}")
        print(f"   ìƒ· íš¨ìœ¨ì„±: {actual_total_shots_final/target_total_shots*100:.1f}%")
        print(f"   ì„±ê³µí•œ íšŒë¡œ: {successful_executions}")
        print(f"   íšŒë¡œë‹¹ í‰ê·  ì‹œê°„: {total_execution_time/successful_executions:.1f}ì´ˆ")
        print(f"   ì‹œê°„ë‹¹ ì²˜ë¦¬ íšŒë¡œ: {successful_executions/(total_execution_time/3600):.1f}ê°œ")
        print(f"   ë°ì´í„° ë¬´ê²°ì„±: {batch_info['data_integrity']}")
        
        # ìµœì  2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ ì¶”ì²œ
        if len(all_results) > 0:
            print("\nğŸ“Š 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ ì„±ëŠ¥ ìš”ì•½:")
            ratio_performance = {}
            
            for result in all_results:
                ratio = result["circuit_info"].get("two_qubit_ratio", 0)
                if ratio not in ratio_performance:
                    ratio_performance[ratio] = {
                        "fidelities": [],
                        "robust_fidelities": [],
                        "error_rates": [],
                        "expressibilities": []
                    }
                
                exec_result = result["execution_result"]
                ratio_performance[ratio]["fidelities"].append(exec_result.get("zero_state_probability", 0))
                ratio_performance[ratio]["robust_fidelities"].append(exec_result.get("robust_fidelity", 0))
                ratio_performance[ratio]["error_rates"].append(exec_result.get("error_rates", {}).get("total_error_rate", 0))
                
                if exec_result.get("expressibility"):
                    ratio_performance[ratio]["expressibilities"].append(
                        exec_result["expressibility"].get("expressibility_value", 0)
                    )
             
             # ë¹„ìœ¨ë³„ í‰ê·  ì„±ëŠ¥ ê³„ì‚°
            for ratio in sorted(ratio_performance.keys()):
                perf = ratio_performance[ratio]
                avg_fidelity = np.mean(perf["fidelities"]) if perf["fidelities"] else 0
                avg_robust_fidelity = np.mean(perf["robust_fidelities"]) if perf["robust_fidelities"] else 0
                avg_error_rate = np.mean(perf["error_rates"]) if perf["error_rates"] else 0
                avg_expressibility = np.mean(perf["expressibilities"]) if perf["expressibilities"] else 0
                
                print(f"   {ratio:.1%} ë¹„ìœ¨:")
                print(f"     í‰ê·  í”¼ë¸ë¦¬í‹°: {avg_fidelity:.6f}")
                print(f"     í‰ê·  Robust í”¼ë¸ë¦¬í‹°: {avg_robust_fidelity:.6f}")
                print(f"     í‰ê·  ì˜¤ë¥˜ìœ¨: {avg_error_rate:.6f}")
                if avg_expressibility > 0:
                    print(f"     í‰ê·  í‘œí˜„ë ¥: {avg_expressibility:.6f}")
             
             # ìµœì  ë¹„ìœ¨ ì¶”ì²œ
            best_ratio = max(ratio_performance.keys(), 
                           key=lambda r: np.mean(ratio_performance[r]["robust_fidelities"]) if ratio_performance[r]["robust_fidelities"] else 0)
            print(f"\nğŸ† ì¶”ì²œ 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨: {best_ratio:.1%} (Robust í”¼ë¸ë¦¬í‹° ê¸°ì¤€)")
            print(f"    Config ê¸°ë°˜ ì ì • ìƒ· ìˆ˜ë¡œ ì¸¡ì •í•˜ì—¬ í†µê³„ì  ì‹ ë¢°ì„± í™•ë³´")
         
        print("\n" + "="*60)
        print("ìµœì í™”ëœ 800ë§Œ ìƒ· ë©”ê°€ì¡ ì‹¤í—˜ ì™„ë£Œ!")
        print(f"ë°ì´í„° ë¬´ê²°ì„±: {batch_info['data_integrity']}")
        print("="*60)
         
    except Exception as e:
        print(f"\nâŒ ë©”ê°€ì¡ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()

def analyze_two_qubit_ratio_results(all_results):
    """2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ ê²°ê³¼ ë¶„ì„ (1800ê°œ íšŒë¡œ)"""
    print("\n===== 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ ì„±ëŠ¥ ë¶„ì„ =====")
    
    # ì„¤ì •ë³„ ê·¸ë£¹í™”
    config_groups = {}
    for result in all_results:
        config_group = result["circuit_info"]["config_group"]
        if config_group not in config_groups:
            config_groups[config_group] = []
        config_groups[config_group].append(result)
    
    print(f"ì´ {len(all_results)}ê°œ íšŒë¡œ ê²°ê³¼ ë¶„ì„")
    print(f"ì„¤ì • ê·¸ë£¹ ìˆ˜: {len(config_groups)}")
    
    # ê° ì„¤ì •ë³„ ìƒì„¸ ë¶„ì„
    for config_group in sorted(config_groups.keys()):
        group_results = config_groups[config_group]
        
        if not group_results:
            continue
            
        # ì„¤ì • ì •ë³´ íŒŒì‹±
        parts = config_group.split('_')
        n_qubits = int(parts[0][1:])  # q5 -> 5
        depth = int(parts[1][1:])     # d10 -> 10
        ratio_percent = int(parts[2][1:])  # r30 -> 30
        ratio = ratio_percent / 100.0
        
        print(f"\nğŸ“Š {config_group} ({n_qubits}íë¹—, ê¹Šì´{depth}, 2íë¹—ë¹„ìœ¨{ratio:.1%}):")
        print(f"   íšŒë¡œ ìˆ˜: {len(group_results)}ê°œ")
        
        # í”¼ë¸ë¦¬í‹° í†µê³„
        fidelities = [r["execution_result"]["zero_state_probability"] for r in group_results]
        print(f"   í”¼ë¸ë¦¬í‹°: {np.mean(fidelities):.6f} Â± {np.std(fidelities):.6f}")
        print(f"   í”¼ë¸ë¦¬í‹° ë²”ìœ„: [{np.min(fidelities):.6f}, {np.max(fidelities):.6f}]")
        
        # ì˜¤ë¥˜ìœ¨ í†µê³„ (ìˆëŠ” ê²½ìš°)
        if "error_rates" in group_results[0]["execution_result"]:
            error_rates = [r["execution_result"]["error_rates"]["total_error_rate"] for r in group_results]
            print(f"   ì´ ì˜¤ë¥˜ìœ¨: {np.mean(error_rates):.6f} Â± {np.std(error_rates):.6f}")
            
            # ë¹„íŠ¸í”Œë¦½ ì˜¤ë¥˜ìœ¨
            bit_flip_rates = [r["execution_result"]["error_rates"]["bit_flip_error_rate"] for r in group_results]
            print(f"   ë¹„íŠ¸í”Œë¦½ ì˜¤ë¥˜ìœ¨: {np.mean(bit_flip_rates):.6f} Â± {np.std(bit_flip_rates):.6f}")
            
            # ìœ„ìƒ ì˜¤ë¥˜ìœ¨
            phase_rates = [r["execution_result"]["error_rates"]["phase_error_rate"] for r in group_results]
            print(f"   ìœ„ìƒ ì˜¤ë¥˜ìœ¨: {np.mean(phase_rates):.6f} Â± {np.std(phase_rates):.6f}")
        
        # ì¸¡ì • ìƒíƒœ ìˆ˜
        measured_states = [r["execution_result"]["measured_states"] for r in group_results]
        print(f"   ì¸¡ì • ìƒíƒœ ìˆ˜: {np.mean(measured_states):.0f} Â± {np.std(measured_states):.0f}")
    
    # 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ ì¢…í•© ë¶„ì„
    print(f"\nğŸ” 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ ì¢…í•© ë¶„ì„:")
    
    ratio_analysis = {}
    for ratio in [0.1, 0.3, 0.5]:
        ratio_results = []
        for result in all_results:
            if abs(result["circuit_info"]["two_qubit_ratio_target"] - ratio) < 0.01:
                ratio_results.append(result)
        
        if ratio_results:
            fidelities = [r["execution_result"]["zero_state_probability"] for r in ratio_results]
            
            ratio_analysis[ratio] = {
                "count": len(ratio_results),
                "fidelity_mean": np.mean(fidelities),
                "fidelity_std": np.std(fidelities)
            }
            
            if "error_rates" in ratio_results[0]["execution_result"]:
                error_rates = [r["execution_result"]["error_rates"]["total_error_rate"] for r in ratio_results]
                ratio_analysis[ratio]["error_rate_mean"] = np.mean(error_rates)
                ratio_analysis[ratio]["error_rate_std"] = np.std(error_rates)
            
            print(f"   {ratio:.1%} ë¹„ìœ¨ ({len(ratio_results)}ê°œ íšŒë¡œ):")
            print(f"     í‰ê·  í”¼ë¸ë¦¬í‹°: {np.mean(fidelities):.6f} Â± {np.std(fidelities):.6f}")
            if "error_rates" in ratio_results[0]["execution_result"]:
                print(f"     í‰ê·  ì˜¤ë¥˜ìœ¨: {np.mean(error_rates):.6f} Â± {np.std(error_rates):.6f}")
    
    # ìµœì  ì„¤ì • ì¶”ì²œ
    print(f"\nğŸ† ì„±ëŠ¥ ë¹„êµ ë° ì¶”ì²œ:")
    
    # ì „ì²´ ê²°ê³¼ì—ì„œ ìµœê³  ì„±ëŠ¥ ì°¾ê¸°
    best_fidelity_result = max(all_results, key=lambda r: r["execution_result"]["zero_state_probability"])
    print(f"   ìµœê³  í”¼ë¸ë¦¬í‹°: {best_fidelity_result['execution_result']['zero_state_probability']:.6f}")
    print(f"     ì„¤ì •: {best_fidelity_result['circuit_info']['config_group']}")
    
    if "error_rates" in all_results[0]["execution_result"]:
        best_error_result = min(all_results, key=lambda r: r["execution_result"]["error_rates"]["total_error_rate"])
        print(f"   ìµœì € ì˜¤ë¥˜ìœ¨: {best_error_result['execution_result']['error_rates']['total_error_rate']:.6f}")
        print(f"     ì„¤ì •: {best_error_result['circuit_info']['config_group']}")
    
    # 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ ì¶”ì²œ
    print(f"\nğŸ’¡ 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ ì¶”ì²œ:")
    if ratio_analysis:
        best_ratio_fidelity = max(ratio_analysis.keys(), key=lambda r: ratio_analysis[r]["fidelity_mean"])
        print(f"   í”¼ë¸ë¦¬í‹° ê¸°ì¤€ ìµœì  ë¹„ìœ¨: {best_ratio_fidelity:.1%}")
        
        if "error_rate_mean" in ratio_analysis[0.1]:
            best_ratio_error = min(ratio_analysis.keys(), key=lambda r: ratio_analysis[r]["error_rate_mean"])
            print(f"   ì˜¤ë¥˜ìœ¨ ê¸°ì¤€ ìµœì  ë¹„ìœ¨: {best_ratio_error:.1%}")
    
    print("="*60)

def save_batch_results(batch_results, filename):
    """ë°°ì¹˜ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    try:
        # ì €ì¥ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
        save_dir = "grid_circuits/mega_results"
        os.makedirs(save_dir, exist_ok=True)
        
        # ì „ì²´ íŒŒì¼ ê²½ë¡œ
        filepath = os.path.join(save_dir, filename)
        
        # ê²°ê³¼ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        serializable_results = []
        for result in batch_results:
            serializable_result = {}
            
            # íšŒë¡œ ì •ë³´ ì²˜ë¦¬ (ì•ˆì „í•œ ë°©ì‹)
            if "circuit_info" in result:
                circuit_info = result["circuit_info"].copy()
                # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                if "params" in circuit_info and hasattr(circuit_info["params"], "__iter__"):
                    try:
                        circuit_info["params"] = [float(p) for p in circuit_info["params"]]
                    except:
                        circuit_info["params"] = []
                serializable_result["circuit_info"] = circuit_info
            
            # ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬ (ì•ˆì „í•œ ë°©ì‹)
            if "execution_result" in result:
                execution_result = result["execution_result"].copy()
                # ë³µì¡í•œ ê°ì²´ ì œê±°
                if "result_obj" in execution_result:
                    del execution_result["result_obj"]
                serializable_result["execution_result"] = execution_result
            
            # ë°°ì¹˜ ì •ë³´ (ì•ˆì „í•œ ì²˜ë¦¬)
            serializable_result["batch_info"] = result.get("batch_info", {
                "batch_id": "unknown",
                "timestamp": datetime.now().isoformat()
            })
            
            # ê¸°íƒ€ í•„ë“œë“¤ ì•ˆì „í•˜ê²Œ ë³µì‚¬
            for key, value in result.items():
                if key not in ["circuit_info", "execution_result", "batch_info"]:
                    try:
                        # JSON ì§ë ¬í™” ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸
                        json.dumps(value, default=str)
                        serializable_result[key] = value
                    except:
                        # ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
                        serializable_result[key] = str(value)
            
            serializable_results.append(serializable_result)
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, indent=2, default=str, ensure_ascii=False)
        
        print(f"  âœ… ë°°ì¹˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath} ({len(batch_results)}ê°œ íšŒë¡œ)")
        
    except Exception as e:
        print(f"  âš ï¸ ë°°ì¹˜ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        # ìƒì„¸í•œ ì˜¤ë¥˜ ì •ë³´ ì¶œë ¥
        import traceback
        print(f"  ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        
        # ìµœì†Œí•œì˜ ì •ë³´ë¼ë„ ì €ì¥ ì‹œë„
        try:
            minimal_data = {
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "circuit_count": len(batch_results),
                "basic_info": [{"circuit_id": i, "status": "error"} for i in range(len(batch_results))]
            }
            
            error_filepath = os.path.join(save_dir, f"error_{filename}")
            with open(error_filepath, 'w', encoding='utf-8') as f:
                json.dump(minimal_data, f, indent=2, ensure_ascii=False)
            print(f"  ğŸ“ ì˜¤ë¥˜ ì •ë³´ ì €ì¥: {error_filepath}")
        except:
            print(f"  âŒ ì˜¤ë¥˜ ì •ë³´ ì €ì¥ë„ ì‹¤íŒ¨")

def save_final_results(all_results, filename):
    """ìµœì¢… ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    try:
        # ì €ì¥ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
        save_dir = "grid_circuits/mega_results"
        os.makedirs(save_dir, exist_ok=True)
        
        # ì „ì²´ íŒŒì¼ ê²½ë¡œ
        filepath = os.path.join(save_dir, filename)
        
        # ê²°ê³¼ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        serializable_results = []
        for result in all_results:
            serializable_result = {}
            
            # íšŒë¡œ ì •ë³´ ì²˜ë¦¬
            circuit_info = result["circuit_info"].copy()
            # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if "params" in circuit_info:
                circuit_info["params"] = [float(p) for p in circuit_info["params"]]
            serializable_result["circuit_info"] = circuit_info
            
            # ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬
            execution_result = result["execution_result"].copy()
            # ë³µì¡í•œ ê°ì²´ ì œê±°
            if "result_obj" in execution_result:
                del execution_result["result_obj"]
            serializable_result["execution_result"] = execution_result
            
            # ë°°ì¹˜ ì •ë³´
            serializable_result["batch_info"] = result.get("batch_info", {})
            
            serializable_results.append(serializable_result)
        
        # ìš”ì•½ í†µê³„ ì¶”ê°€
        summary_stats = generate_summary_statistics(all_results)
        
        final_data = {
            "experiment_info": {
                "total_circuits": len(all_results),
                "experiment_type": "two_qubit_ratio_test",
                "timestamp": datetime.now().isoformat(),
                "settings": {
                    "n_qubits_list": [5, 7, 10],
                    "depth_list": [5, 10, 15],
                    "two_qubit_ratios": [0.1, 0.3, 0.5],
                    "circuits_per_config": 200
                }
            },
            "summary_statistics": summary_stats,
            "detailed_results": serializable_results
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, indent=2, default=str, ensure_ascii=False)
        
        print(f"âœ… ìµœì¢… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath} ({len(all_results)}ê°œ íšŒë¡œ)")
        
    except Exception as e:
        print(f"âš ï¸ ìµœì¢… ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()

def generate_summary_statistics(all_results):
    """
    800ë§Œ ìƒ· ì‹¤í—˜ ê²°ê³¼ì˜ ìš”ì•½ í†µê³„ ìƒì„±
    
    Args:
        all_results (list): ëª¨ë“  ì‹¤í–‰ ê²°ê³¼
        
    Returns:
        dict: ìš”ì•½ í†µê³„
    """
    if not all_results:
        return {"error": "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."}
    
    print(f"\nğŸ“Š {len(all_results)}ê°œ íšŒë¡œ ê²°ê³¼ì˜ ìš”ì•½ í†µê³„ ìƒì„± ì¤‘...")
    
    # ê¸°ë³¸ í†µê³„
    summary = {
        "experiment_info": {
            "total_circuits": len(all_results),
            "timestamp": datetime.now().isoformat(),
            "experiment_type": "800ë§Œ ìƒ· 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ í…ŒìŠ¤íŠ¸"
        },
        "circuit_statistics": {},
        "performance_statistics": {},
        "two_qubit_ratio_analysis": {},
        "error_analysis": {},
        "recommendations": {}
    }
    
    # íšŒë¡œ í†µê³„
    n_qubits_list = [r["circuit_info"]["n_qubits"] for r in all_results]
    depths = [r["circuit_info"]["depth"] for r in all_results]
    two_qubit_ratios = [r["circuit_info"].get("two_qubit_ratio", 0) for r in all_results]
    
    summary["circuit_statistics"] = {
        "qubit_range": {"min": min(n_qubits_list), "max": max(n_qubits_list)},
        "depth_range": {"min": min(depths), "max": max(depths)},
        "two_qubit_ratio_range": {"min": min(two_qubit_ratios), "max": max(two_qubit_ratios)},
        "unique_configurations": len(set((q, d, r) for q, d, r in zip(n_qubits_list, depths, two_qubit_ratios)))
    }
    
    # ì„±ëŠ¥ í†µê³„
    fidelities = []
    robust_fidelities = []
    total_error_rates = []
    expressibilities = []
    execution_times = []
    
    for result in all_results:
        exec_result = result["execution_result"]
        
        fidelities.append(exec_result.get("zero_state_probability", 0))
        robust_fidelities.append(exec_result.get("robust_fidelity", 0))
        
        error_rates = exec_result.get("error_rates", {})
        total_error_rates.append(error_rates.get("total_error_rate", 0))
        
        if exec_result.get("expressibility"):
            expressibilities.append(exec_result["expressibility"].get("expressibility_value", 0))
        
        execution_times.append(result.get("execution_time", 0))
    
    summary["performance_statistics"] = {
        "fidelity": {
            "mean": float(np.mean(fidelities)),
            "std": float(np.std(fidelities)),
            "min": float(np.min(fidelities)),
            "max": float(np.max(fidelities)),
            "median": float(np.median(fidelities))
        },
        "robust_fidelity": {
            "mean": float(np.mean(robust_fidelities)),
            "std": float(np.std(robust_fidelities)),
            "min": float(np.min(robust_fidelities)),
            "max": float(np.max(robust_fidelities)),
            "median": float(np.median(robust_fidelities))
        },
        "total_error_rate": {
            "mean": float(np.mean(total_error_rates)),
            "std": float(np.std(total_error_rates)),
            "min": float(np.min(total_error_rates)),
            "max": float(np.max(total_error_rates)),
            "median": float(np.median(total_error_rates))
        }
    }
    
    if expressibilities:
        summary["performance_statistics"]["expressibility"] = {
            "mean": float(np.mean(expressibilities)),
            "std": float(np.std(expressibilities)),
            "min": float(np.min(expressibilities)),
            "max": float(np.max(expressibilities)),
            "median": float(np.median(expressibilities))
        }
    
    # 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨ë³„ ë¶„ì„
    ratio_groups = {}
    for result in all_results:
        ratio = result["circuit_info"].get("two_qubit_ratio", 0)
        if ratio not in ratio_groups:
            ratio_groups[ratio] = {
                "fidelities": [],
                "robust_fidelities": [],
                "error_rates": [],
                "expressibilities": [],
                "count": 0
            }
        
        exec_result = result["execution_result"]
        ratio_groups[ratio]["fidelities"].append(exec_result.get("zero_state_probability", 0))
        ratio_groups[ratio]["robust_fidelities"].append(exec_result.get("robust_fidelity", 0))
        ratio_groups[ratio]["error_rates"].append(exec_result.get("error_rates", {}).get("total_error_rate", 0))
        
        if exec_result.get("expressibility"):
            ratio_groups[ratio]["expressibilities"].append(exec_result["expressibility"].get("expressibility_value", 0))
        
        ratio_groups[ratio]["count"] += 1
    
    # ë¹„ìœ¨ë³„ í†µê³„ ê³„ì‚°
    for ratio, data in ratio_groups.items():
        summary["two_qubit_ratio_analysis"][f"{ratio:.1%}"] = {
            "count": data["count"],
            "fidelity_mean": float(np.mean(data["fidelities"])),
            "robust_fidelity_mean": float(np.mean(data["robust_fidelities"])),
            "error_rate_mean": float(np.mean(data["error_rates"])),
            "fidelity_std": float(np.std(data["fidelities"])),
            "robust_fidelity_std": float(np.std(data["robust_fidelities"])),
            "error_rate_std": float(np.std(data["error_rates"]))
        }
        
        if data["expressibilities"]:
            summary["two_qubit_ratio_analysis"][f"{ratio:.1%}"]["expressibility_mean"] = float(np.mean(data["expressibilities"]))
            summary["two_qubit_ratio_analysis"][f"{ratio:.1%}"]["expressibility_std"] = float(np.std(data["expressibilities"]))
    
    # ì˜¤ë¥˜ ë¶„ì„
    high_error_circuits = [r for r in all_results if r["execution_result"].get("error_rates", {}).get("total_error_rate", 0) > 0.1]
    low_fidelity_circuits = [r for r in all_results if r["execution_result"].get("zero_state_probability", 0) < 0.5]
    
    summary["error_analysis"] = {
        "high_error_circuits_count": len(high_error_circuits),
        "high_error_circuits_percentage": len(high_error_circuits) / len(all_results) * 100,
        "low_fidelity_circuits_count": len(low_fidelity_circuits),
        "low_fidelity_circuits_percentage": len(low_fidelity_circuits) / len(all_results) * 100
    }
    
    # ì¶”ì²œì‚¬í•­
    best_ratio_by_fidelity = max(ratio_groups.keys(), key=lambda r: np.mean(ratio_groups[r]["fidelities"]))
    best_ratio_by_robust_fidelity = max(ratio_groups.keys(), key=lambda r: np.mean(ratio_groups[r]["robust_fidelities"]))
    best_ratio_by_low_error = min(ratio_groups.keys(), key=lambda r: np.mean(ratio_groups[r]["error_rates"]))
    
    summary["recommendations"] = {
        "best_ratio_for_fidelity": f"{best_ratio_by_fidelity:.1%}",
        "best_ratio_for_robust_fidelity": f"{best_ratio_by_robust_fidelity:.1%}",
        "best_ratio_for_low_error": f"{best_ratio_by_low_error:.1%}",
        "overall_recommendation": f"{best_ratio_by_robust_fidelity:.1%}",
        "recommendation_reason": "Robust í”¼ë¸ë¦¬í‹°ê°€ ë…¸ì´ì¦ˆ í™˜ê²½ì—ì„œ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì§€í‘œì…ë‹ˆë‹¤."
    }
    
    print(f"âœ… ìš”ì•½ í†µê³„ ìƒì„± ì™„ë£Œ")
    print(f"   ë¶„ì„ëœ íšŒë¡œ ìˆ˜: {len(all_results)}")
    print(f"   ê³ ìœ  ì„¤ì • ìˆ˜: {summary['circuit_statistics']['unique_configurations']}")
    print(f"   í‰ê·  í”¼ë¸ë¦¬í‹°: {summary['performance_statistics']['fidelity']['mean']:.6f}")
    print(f"   í‰ê·  Robust í”¼ë¸ë¦¬í‹°: {summary['performance_statistics']['robust_fidelity']['mean']:.6f}")
    print(f"   ì¶”ì²œ 2íë¹— ê²Œì´íŠ¸ ë¹„ìœ¨: {summary['recommendations']['overall_recommendation']}")
    
    return summary

if __name__ == "__main__":
    print("ğŸš€ Mega Job Generator ì‹œì‘!")
    print("ğŸ“ ë””ë ‰í† ë¦¬ ì„¤ì • ì¤‘...")
    setup_directories()
    print("\nğŸ¯ ë©”ê°€ì¡ ì‹¤í–‰ ì‹œì‘!")
    run_mega_job_generator() 