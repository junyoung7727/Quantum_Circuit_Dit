#!/usr/bin/env python3
"""
Classical Shadow ê¸°ë°˜ í‘œí˜„ë ¥(Expressibility) ì¸¡ì • ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ì–‘ì íšŒë¡œì˜ í‘œí˜„ë ¥ì„ Classical Shadow ë°©ë²•ë¡ ì„ ì‚¬ìš©í•˜ì—¬ ì¸¡ì •í•©ë‹ˆë‹¤.
ê¸°ì¡´ measure_express.pyì™€ì˜ í˜¸í™˜ì„±ë„ ì œê³µí•©ë‹ˆë‹¤.
"""

import numpy as np
import pennylane as qml
import random
import time
from scipy.stats import norm
from config import config, get_shadow_params


class ExpressibilityCalculator:
    """Classical Shadow ê¸°ë°˜ í‘œí˜„ë ¥ ê³„ì‚°ê¸°"""
    
    def __init__(self):
        """í‘œí˜„ë ¥ ê³„ì‚°ê¸° ì´ˆê¸°í™”"""
        self.config = config
    
    def calculate_expressibility(self, circuit_info, S=None, M=None, metric='classical_shadow', sigma=1.0):
        """
        Classical Shadow ë°©ë²•ë¡ ì„ ì‚¬ìš©í•œ ì•ˆì‚¬ì¸  í‘œí˜„ë ¥ ê³„ì‚°
        
        Args:
            circuit_info (dict): íšŒë¡œ ì •ë³´
            S (int): íŒŒë¼ë¯¸í„° ìƒ˜í”Œ ìˆ˜ (Noneì´ë©´ ìë™ ì„¤ì •)
            M (int): Shadow í¬ê¸° (Noneì´ë©´ ìë™ ì„¤ì •)
            metric (str): 'classical_shadow' (ê¸°ë³¸ê°’)
            sigma (float): ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (í˜¸í™˜ì„± ìœ ì§€)
            
        Returns:
            dict: í‘œí˜„ë ¥ ì¸¡ì • ê²°ê³¼
        """
        n_qubits = circuit_info["n_qubits"]
        
        # ì¤‘ì•™ ì„¤ì •ì—ì„œ ìµœì í™”ëœ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
        if S is None or M is None:
            auto_S, auto_M = get_shadow_params(n_qubits)
            S = S if S is not None else auto_S
            M = M if M is not None else auto_M
            print(f"ğŸ”§ ìë™ ì„¤ì • ì ìš©: {n_qubits} íë¹— â†’ Shadow({S}, {M})")
        
        start_time = time.time()
        
        print(f"\n===== Classical Shadow ê¸°ë°˜ í‘œí˜„ë ¥ ì¸¡ì • =====")
        print(f"íë¹— ìˆ˜: {n_qubits}, íŒŒë¼ë¯¸í„° ìƒ˜í”Œ ìˆ˜: {S}, Shadow í¬ê¸°: {M}")
        print(f"ì´ ì¸¡ì • íšŸìˆ˜: {S * M}")
        print(f"ë©”ëª¨ë¦¬ ì œí•œ: ìµœëŒ€ {config.classical_shadow.max_shadow_qubits} íë¹—")
        
        # 1. ì—¬ëŸ¬ íŒŒë¼ë¯¸í„°ì— ëŒ€í•´ Classical Shadow ìˆ˜ì§‘
        all_shadow_data = []
        
        for s in range(S):
            if s % 10 == 0:
                print(f"Shadow ìˆ˜ì§‘ ì¤‘: {s}/{S}")
            
            # ëœë¤ íŒŒë¼ë¯¸í„° ìƒì„±
            param_count = len(circuit_info["params"])
            if param_count > 0:
                rand_params = 2 * np.pi * np.random.rand(param_count)
            else:
                rand_params = []
            
            # Classical Shadow ìˆ˜ì§‘
            shadow_data = self._collect_classical_shadow(circuit_info, rand_params, n_qubits, M)
            all_shadow_data.append(shadow_data)
        
        # 2. Shadow ë°ì´í„°ì—ì„œ Pauli ê¸°ëŒ“ê°’ ì¶”ì •
        estimated_moments = self._estimate_pauli_expectations_from_shadows(all_shadow_data, n_qubits)
        
        # 3. Haar ëœë¤ ë¶„í¬ì˜ ì´ë¡ ì  Pauli ê¸°ëŒ“ê°’
        haar_moments = self._get_haar_pauli_expectations(n_qubits)
        
        # 4. Classical Shadow ê¸°ë°˜ ê±°ë¦¬ ê³„ì‚°
        distance = self._calculate_shadow_distance(estimated_moments, haar_moments)
        
        # 5. Classical Shadow ì´ë¡  ê¸°ë°˜ ì‹ ë¢°êµ¬ê°„
        confidence_interval = self._calculate_shadow_confidence_interval(estimated_moments, S, M, n_qubits)
        
        # ì‹¤í–‰ ì‹œê°„
        run_time = time.time() - start_time
        
        # í‘œí˜„ë ¥ ì ìˆ˜ ê³„ì‚° (ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ì¢‹ì€ í‘œí˜„ë ¥)
        # Classical Shadowì—ì„œ Pauli ê¸°ëŒ“ê°’ì˜ ë²”ìœ„ëŠ” [-1, 1]ì´ë¯€ë¡œ 
        # L2 ê±°ë¦¬ì˜ ìµœëŒ€ê°’ì€ ëŒ€ëµ sqrt(ì—°ì‚°ì ìˆ˜ * 4) ì •ë„
        num_operators = len(estimated_moments)
        max_possible_distance = np.sqrt(num_operators * 4)  # ë” í˜„ì‹¤ì ì¸ ìµœëŒ€ ê±°ë¦¬
        
        # ê±°ë¦¬ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° (0~1 ë²”ìœ„, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        if max_possible_distance > 0:
            normalized_distance = distance / max_possible_distance
            # ì§€ìˆ˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ë¯¼ê°í•œ ì ìˆ˜ ê³„ì‚°
            expressibility_score = np.exp(-normalized_distance)
        else:
            expressibility_score = 0.0
        
        # ì¶”ê°€ì ì¸ ì •ê·œí™”: íë¹— ìˆ˜ì— ë”°ë¥¸ ì¡°ì •
        # íë¹— ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ë” ì–´ë ¤ìš°ë¯€ë¡œ ë³´ì •
        qubit_factor = 1.0 / (1.0 + 0.1 * n_qubits)  # íë¹— ìˆ˜ ì¦ê°€ì— ë”°ë¥¸ ë‚œì´ë„ ë³´ì •
        expressibility_score = expressibility_score * qubit_factor
        
        # [0,1] ë²”ìœ„ë¡œ í´ë¦¬í•‘
        expressibility_score = max(0.0, min(1.0, expressibility_score))
        
        # ê²°ê³¼ ë³´ê³ ì„œ ì¤€ë¹„
        result = {
            "method": "classical_shadow",
            "n_qubits": n_qubits,
            "samples": S,
            "shadow_size": M,
            "distance": distance,
            "expressibility_score": expressibility_score,
            "confidence_interval": confidence_interval,
            "total_measurements": S * M,
            "run_time": run_time,
            "scalability": "O(log(n))",
            "estimated_operators": len(estimated_moments),
            "theoretical_advantage": f"Classical: O(4^n) â†’ Shadow: O(log(n))"
        }
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n===== Classical Shadow í‘œí˜„ë ¥ ì¸¡ì • ê²°ê³¼ =====")
        print(f"ì¶”ì •ëœ Pauli ì—°ì‚°ì ìˆ˜: {len(estimated_moments)}")
        print(f"Shadow ê¸°ë°˜ ê±°ë¦¬: {distance:.4e}")
        print(f"í‘œí˜„ë ¥ ì ìˆ˜: {expressibility_score:.4f} (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)")
        print(f"95% ì‹ ë¢°êµ¬ê°„: [{confidence_interval[0]:.4e}, {confidence_interval[1]:.4e}]")
        print(f"ì´ ì¸¡ì • íšŸìˆ˜: {S * M}")
        print(f"ì‹¤í–‰ ì‹œê°„: {run_time:.1f}ì´ˆ")
        print(f"í™•ì¥ì„±: {result['scalability']} (ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ ì§€ìˆ˜ì  ê°œì„ )")
        print(f"ì´ë¡ ì  ê¸°ëŒ€: ê¹Šì´ ì¦ê°€ â†’ ê±°ë¦¬ ê°ì†Œ (Haar ëœë¤ì— ìˆ˜ë ´)")
        
        return result
    
    def _collect_classical_shadow(self, circuit_info, params, n_qubits, shadow_size):
        """
        Classical Shadow ë°ì´í„° ìˆ˜ì§‘
        
        Args:
            circuit_info (dict): íšŒë¡œ ì •ë³´
            params (array): íšŒë¡œ íŒŒë¼ë¯¸í„°
            n_qubits (int): íë¹— ìˆ˜
            shadow_size (int): Shadow í¬ê¸°
            
        Returns:
            dict: Shadow ë°ì´í„° (ì¸¡ì • ê¸°ì €ì™€ ê²°ê³¼)
        """
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ íë¹— ìˆ˜ ì œí•œ
        max_shadow_qubits = config.classical_shadow.max_shadow_qubits
        if n_qubits > max_shadow_qubits:
            print(f"âš ï¸ Shadow ìˆ˜ì§‘: {n_qubits} â†’ {max_shadow_qubits} íë¹—ìœ¼ë¡œ ì œí•œ")
            effective_n_qubits = max_shadow_qubits
        else:
            effective_n_qubits = n_qubits
        
        # ê° ìƒ·ë§ˆë‹¤ ê°œë³„ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ì •í™•í•œ Classical Shadow ìˆ˜ì§‘
        all_measurements = []
        all_measurement_bases = []
        
        # ì‹œë®¬ë ˆì´í„° ì¥ì¹˜ ì„¤ì • (ìƒ· ìˆ˜ 1ë¡œ ì„¤ì •í•˜ì—¬ ê°œë³„ ì‹¤í–‰)
        device = qml.device("default.qubit", wires=effective_n_qubits, shots=1)
        
        for shot in range(shadow_size):
            # ì´ ìƒ·ì— ëŒ€í•œ ëœë¤ ì¸¡ì • ê¸°ì € ìƒì„±
            shot_bases = [random.choice(['X', 'Y', 'Z']) for _ in range(effective_n_qubits)]
            
            @qml.qnode(device)
            def shadow_circuit():
                # 1. ì›ë³¸ íšŒë¡œ ì ìš©
                gates = circuit_info["gates"]
                wires_list = circuit_info["wires_list"]
                params_idx = circuit_info["params_idx"]
                
                for i, (gate, wires) in enumerate(zip(gates, wires_list)):
                    # íë¹— ë²”ìœ„ í™•ì¸
                    if any(w >= effective_n_qubits for w in wires):
                        continue
                    
                    if gate == "H":
                        qml.Hadamard(wires=wires[0])
                    elif gate == "X":
                        qml.PauliX(wires=wires[0])
                    elif gate == "Y":
                        qml.PauliY(wires=wires[0])
                    elif gate == "Z":
                        qml.PauliZ(wires=wires[0])
                    elif gate == "S":
                        qml.S(wires=wires[0])
                    elif gate == "T":
                        qml.T(wires=wires[0])
                    elif gate == "RZ":
                        if i in params_idx:
                            param_idx = params_idx.index(i)
                            qml.RZ(params[param_idx], wires=wires[0])
                    elif gate == "CNOT":
                        if len(wires) >= 2:
                            qml.CNOT(wires=[wires[0], wires[1]])
                
                # 2. ì´ ìƒ·ì— ëŒ€í•œ ëœë¤ Clifford ì¸¡ì • ì ìš©
                for i in range(effective_n_qubits):
                    basis = shot_bases[i]
                    
                    # ì„ íƒëœ ê¸°ì €ë¡œ íšŒì „
                    if basis == 'X':
                        qml.Hadamard(wires=i)  # Z â†’ X ê¸°ì €
                    elif basis == 'Y':
                        qml.RX(-np.pi/2, wires=i)  # Z â†’ Y ê¸°ì €
                    # Z ê¸°ì €ëŠ” íšŒì „ ì—†ìŒ
                
                # 3. ê³„ì‚° ê¸°ì €ì—ì„œ ì¸¡ì •
                return qml.sample(wires=range(effective_n_qubits))
            
            # ì´ ìƒ· ì‹¤í–‰
            measurement = shadow_circuit()
            
            # ê²°ê³¼ ì €ì¥ (1ì°¨ì› ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜)
            if hasattr(measurement, 'tolist'):
                measurement_list = measurement.tolist()
            else:
                measurement_list = list(measurement)
            
            all_measurements.append(measurement_list)
            all_measurement_bases.append(shot_bases)
        
        # Shadow ë°ì´í„° êµ¬ì¡°í™”
        shadow_data = {
            "measurements": all_measurements,  # ì¸¡ì • ê²°ê³¼ (0/1 ë¹„íŠ¸ì—´)
            "bases": all_measurement_bases,  # ê° íë¹—ì˜ ì¸¡ì • ê¸°ì €
            "n_qubits": effective_n_qubits,
            "shadow_size": shadow_size
        }
        
        return shadow_data
    
    def _estimate_pauli_expectations_from_shadows(self, all_shadow_data, n_qubits):
        """
        Classical Shadow ë°ì´í„°ì—ì„œ Pauli ê¸°ëŒ“ê°’ ì¶”ì •
        
        Args:
            all_shadow_data (list): ëª¨ë“  Shadow ë°ì´í„°
            n_qubits (int): íë¹— ìˆ˜
            
        Returns:
            dict: ì¶”ì •ëœ Pauli ê¸°ëŒ“ê°’
        """
        estimated_expectations = {}
        
        # íš¨ê³¼ì ì¸ íë¹— ìˆ˜ (Shadow ìˆ˜ì§‘ ì‹œ ì œí•œëœ ìˆ˜)
        effective_n_qubits = min(n_qubits, config.classical_shadow.max_shadow_qubits)
        
        # Shadow ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        valid_shadow_data = []
        for i, shadow_data in enumerate(all_shadow_data):
            if not isinstance(shadow_data, dict):
                print(f"âš ï¸ Shadow ë°ì´í„° {i}: ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜, ê±´ë„ˆëœ€")
                continue
            
            # measurements í‚¤ í™•ì¸
            if "measurements" not in shadow_data:
                print(f"âš ï¸ Shadow ë°ì´í„° {i}: 'measurements' í‚¤ ì—†ìŒ, ê±´ë„ˆëœ€")
                continue
            
            # bases í‚¤ í™•ì¸
            if "bases" not in shadow_data:
                print(f"âš ï¸ Shadow ë°ì´í„° {i}: 'bases' í‚¤ ì—†ìŒ, ê±´ë„ˆëœ€")
                continue
            
            # ë°ì´í„° êµ¬ì¡° í™•ì¸
            measurements = shadow_data["measurements"]
            bases = shadow_data["bases"]
            
            if not isinstance(measurements, list) or not isinstance(bases, list):
                print(f"âš ï¸ Shadow ë°ì´í„° {i}: measurements ë˜ëŠ” basesê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜, ê±´ë„ˆëœ€")
                continue
            
            if len(measurements) != len(bases):
                print(f"âš ï¸ Shadow ë°ì´í„° {i}: measurementsì™€ bases ê¸¸ì´ ë¶ˆì¼ì¹˜, ê±´ë„ˆëœ€")
                continue
            
            valid_shadow_data.append(shadow_data)
        
        if not valid_shadow_data:
            print("âš ï¸ ìœ íš¨í•œ Shadow ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ ë°˜í™˜")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ëª¨ë“  Pauli ê¸°ëŒ“ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •
            for qubit_idx in range(effective_n_qubits):
                for pauli_op in ['X', 'Y', 'Z']:
                    op_name = f"{pauli_op}{qubit_idx}"
                    estimated_expectations[op_name] = 0.0
            return estimated_expectations
        
        print(f"âœ“ {len(valid_shadow_data)}/{len(all_shadow_data)} Shadow ë°ì´í„°ê°€ ìœ íš¨í•¨")
        
        # 1-local Pauli ì—°ì‚°ì ì¶”ì •
        for qubit_idx in range(effective_n_qubits):
            for pauli_op in ['X', 'Y', 'Z']:
                op_name = f"{pauli_op}{qubit_idx}"
                
                # ëª¨ë“  Shadowì—ì„œ í•´ë‹¹ ì—°ì‚°ìì˜ ê¸°ëŒ“ê°’ ì¶”ì •
                estimates = []
                
                for shadow_data in valid_shadow_data:
                    try:
                        measurements = shadow_data["measurements"]
                        bases = shadow_data["bases"]
                        
                        # Classical Shadow ê³µì‹ ì ìš©
                        estimate = self._classical_shadow_estimator(
                            measurements, bases, qubit_idx, pauli_op
                        )
                        estimates.append(estimate)
                    except Exception as e:
                        print(f"âš ï¸ Shadow ì¶”ì • ì¤‘ ì˜¤ë¥˜ ({op_name}): {str(e)}")
                        continue
                
                # ëª¨ë“  ì¶”ì •ê°’ì˜ í‰ê· 
                if estimates:
                    estimated_expectations[op_name] = np.mean(estimates)
                else:
                    estimated_expectations[op_name] = 0.0
        
        # 2-local Pauli ì—°ì‚°ì ì¶”ì • (ì¤‘ìš”í•œ ê²ƒë§Œ ì„ íƒì ìœ¼ë¡œ)
        if effective_n_qubits <= config.classical_shadow.max_2local_qubits:  # ì‘ì€ ì‹œìŠ¤í…œì—ì„œë§Œ 2-local ê³„ì‚°
            # ì´ì›ƒí•œ íë¹— ìŒë§Œ ê³ ë ¤
            for i in range(effective_n_qubits - 1):
                j = i + 1
                for pauli1, pauli2 in [('X', 'X'), ('Y', 'Y'), ('Z', 'Z')]:
                    op_name = f"{pauli1}{i}{pauli2}{j}"
                    
                    estimates = []
                    for shadow_data in valid_shadow_data:
                        try:
                            measurements = shadow_data["measurements"]
                            bases = shadow_data["bases"]
                            
                            # 2-local Classical Shadow ì¶”ì •
                            estimate = self._classical_shadow_2local_estimator(
                                measurements, bases, i, j, pauli1, pauli2
                            )
                            estimates.append(estimate)
                        except Exception as e:
                            print(f"âš ï¸ 2-local Shadow ì¶”ì • ì¤‘ ì˜¤ë¥˜ ({op_name}): {str(e)}")
                            continue
                    
                    if estimates:
                        estimated_expectations[op_name] = np.mean(estimates)
                    else:
                        estimated_expectations[op_name] = 0.0
        
        return estimated_expectations
    
    def _classical_shadow_estimator(self, measurements, bases, qubit_idx, target_pauli):
        """
        Classical Shadow 1-local ì¶”ì •ê¸°
        
        Args:
            measurements: ì¸¡ì • ê²°ê³¼ ë°°ì—´
            bases: ì¸¡ì • ê¸°ì € ë°°ì—´
            qubit_idx: íƒ€ê²Ÿ íë¹— ì¸ë±ìŠ¤
            target_pauli: íƒ€ê²Ÿ Pauli ì—°ì‚°ì ('X', 'Y', 'Z')
            
        Returns:
            float: ì¶”ì •ëœ ê¸°ëŒ“ê°’
        """
        estimates = []
        
        for shot_idx, (measurement, shot_bases) in enumerate(zip(measurements, bases)):
            # í•´ë‹¹ íë¹—ì˜ ì¸¡ì • ê¸°ì € í™•ì¸
            if qubit_idx >= len(shot_bases) or qubit_idx >= len(measurement):
                continue
                
            measured_basis = shot_bases[qubit_idx]
            measured_outcome = measurement[qubit_idx]
            
            # Classical Shadow ê³µì‹: 3 * Î´_{b,Ïƒ} * (2m - 1)
            # ì—¬ê¸°ì„œ bëŠ” ì¸¡ì • ê¸°ì €, ÏƒëŠ” íƒ€ê²Ÿ Pauli, mì€ ì¸¡ì • ê²°ê³¼ (0 ë˜ëŠ” 1)
            if measured_basis == target_pauli:
                # ì¸¡ì • ê¸°ì €ì™€ íƒ€ê²Ÿì´ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ë§Œ ê¸°ì—¬
                # ì¸¡ì • ê²°ê³¼ 0 â†’ +1, ì¸¡ì • ê²°ê³¼ 1 â†’ -1
                classical_outcome = 1 if measured_outcome == 0 else -1
                shadow_estimate = 3 * classical_outcome  # Classical Shadow ê³µì‹
                estimates.append(shadow_estimate)
        
        # ìœ íš¨í•œ ì¶”ì •ê°’ì´ ìˆìœ¼ë©´ í‰ê· , ì—†ìœ¼ë©´ 0
        if estimates:
            return np.mean(estimates)
        else:
            # í•´ë‹¹ ê¸°ì €ë¡œ ì¸¡ì •ëœ ìƒ·ì´ ì—†ìœ¼ë©´ 0 ë°˜í™˜
            return 0.0
    
    def _classical_shadow_2local_estimator(self, measurements, bases, qubit1, qubit2, pauli1, pauli2):
        """
        Classical Shadow 2-local ì¶”ì •ê¸°
        
        Args:
            measurements: ì¸¡ì • ê²°ê³¼ ë°°ì—´
            bases: ì¸¡ì • ê¸°ì € ë°°ì—´
            qubit1, qubit2: íƒ€ê²Ÿ íë¹— ì¸ë±ìŠ¤ë“¤
            pauli1, pauli2: íƒ€ê²Ÿ Pauli ì—°ì‚°ìë“¤
            
        Returns:
            float: ì¶”ì •ëœ 2-local ê¸°ëŒ“ê°’
        """
        estimates = []
        
        for shot_idx, (measurement, shot_bases) in enumerate(zip(measurements, bases)):
            # ë‘ íë¹—ì˜ ì¸¡ì • ê¸°ì € í™•ì¸
            basis1 = shot_bases[qubit1] if isinstance(shot_bases, list) else shot_bases
            basis2 = shot_bases[qubit2] if isinstance(shot_bases, list) else shot_bases
            
            outcome1 = measurement[qubit1]
            outcome2 = measurement[qubit2]
            
            # ë‘ íë¹— ëª¨ë‘ ì˜¬ë°”ë¥¸ ê¸°ì €ë¡œ ì¸¡ì •ëœ ê²½ìš°ë§Œ ê¸°ì—¬
            if basis1 == pauli1 and basis2 == pauli2:
                classical1 = 1 if outcome1 == 0 else -1
                classical2 = 1 if outcome2 == 0 else -1
                
                # 2-local Classical Shadow ê³µì‹: 9 * (2m1-1) * (2m2-1)
                shadow_estimate = 9 * classical1 * classical2
                estimates.append(shadow_estimate)
        
        return np.mean(estimates) if estimates else 0.0
    
    def _get_haar_pauli_expectations(self, n_qubits):
        """
        Haar ëœë¤ ë¶„í¬ì˜ ì´ë¡ ì  Pauli ê¸°ëŒ“ê°’
        
        Args:
            n_qubits (int): íë¹— ìˆ˜
            
        Returns:
            dict: Haar ëœë¤ Pauli ê¸°ëŒ“ê°’ (ëª¨ë‘ 0)
        """
        haar_expectations = {}
        
        # íš¨ê³¼ì ì¸ íë¹— ìˆ˜
        effective_n_qubits = min(n_qubits, config.classical_shadow.max_shadow_qubits)
        
        # 1-local Pauli ì—°ì‚°ì (ëª¨ë‘ 0)
        for qubit_idx in range(effective_n_qubits):
            for pauli_op in ['X', 'Y', 'Z']:
                op_name = f"{pauli_op}{qubit_idx}"
                haar_expectations[op_name] = 0.0
        
        # 2-local Pauli ì—°ì‚°ì (ëª¨ë‘ 0)
        if effective_n_qubits <= config.classical_shadow.max_2local_qubits:
            for i in range(effective_n_qubits - 1):
                j = i + 1
                for pauli1, pauli2 in [('X', 'X'), ('Y', 'Y'), ('Z', 'Z')]:
                    op_name = f"{pauli1}{i}{pauli2}{j}"
                    haar_expectations[op_name] = 0.0
        
        return haar_expectations
    
    def _calculate_shadow_distance(self, estimated_moments, haar_moments):
        """
        Classical Shadow ê¸°ë°˜ ê±°ë¦¬ ê³„ì‚°
        
        Args:
            estimated_moments (dict): ì¶”ì •ëœ ëª¨ë©˜íŠ¸
            haar_moments (dict): Haar ëœë¤ ëª¨ë©˜íŠ¸
            
        Returns:
            float: ê³„ì‚°ëœ ê±°ë¦¬
        """
        if not estimated_moments:
            return 0.0
        
        # ê³µí†µ í‚¤ ì¶”ì¶œ
        common_keys = set(estimated_moments.keys()) & set(haar_moments.keys())
        
        if len(common_keys) == 0:
            return 0.0
        
        # L2 ê±°ë¦¬ ê³„ì‚° (Classical Shadowì— ì í•©)
        estimated_vec = np.array([estimated_moments[k] for k in common_keys])
        haar_vec = np.array([haar_moments[k] for k in common_keys])
        
        # L2 ê±°ë¦¬
        distance = np.sqrt(np.sum((estimated_vec - haar_vec)**2))
        
        return distance
    
    def _calculate_shadow_confidence_interval(self, estimated_moments, S, M, n_qubits, alpha=0.05):
        """
        Classical Shadow ì´ë¡  ê¸°ë°˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
        
        Args:
            estimated_moments (dict): ì¶”ì •ëœ ëª¨ë©˜íŠ¸
            S (int): íŒŒë¼ë¯¸í„° ìƒ˜í”Œ ìˆ˜
            M (int): Shadow í¬ê¸°
            n_qubits (int): íë¹— ìˆ˜
            alpha (float): ì‹ ë¢°ìˆ˜ì¤€
            
        Returns:
            tuple: (í•˜í•œ, ìƒí•œ) ì‹ ë¢°êµ¬ê°„
        """
        if not estimated_moments:
            return [0.0, 0.0]
        
        # Classical Shadow ì´ë¡ ì— ë”°ë¥¸ ë¶„ì‚° ì¶”ì •
        # Var[O] â‰¤ 3^k / T, ì—¬ê¸°ì„œ këŠ” locality, TëŠ” ì´ Shadow ìˆ˜
        k = 1  # ì£¼ë¡œ 1-local ì—°ì‚°ì ì‚¬ìš©
        total_shadows = S * M
        
        # ë¶„ì‚° ìƒí•œ
        variance_bound = (3**k) / total_shadows
        std_error = np.sqrt(variance_bound)
        
        # í‰ê·  ê±°ë¦¬ê°’
        mean_distance = np.sqrt(np.sum([v**2 for v in estimated_moments.values()]))
        
        # 95% ì‹ ë¢°êµ¬ê°„
        z = norm.ppf(1 - alpha/2)
        
        low = max(0, mean_distance - z * std_error)
        high = mean_distance + z * std_error
        
        return [low, high]
    
    # measure_express.py í˜¸í™˜ì„± í•¨ìˆ˜ë“¤
    def _estimate_moments(self, shadow_data_list, n_qubits):
        """
        measure_express.py í˜¸í™˜ì„±ì„ ìœ„í•œ ëª¨ë©˜íŠ¸ ì¶”ì • í•¨ìˆ˜
        Classical Shadow ë°ì´í„°ë¥¼ ê¸°ì¡´ ëª¨ë©˜íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Args:
            shadow_data_list (list): Classical Shadow ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            n_qubits (int): íë¹— ìˆ˜
            
        Returns:
            tuple: (moments_1, moments_2) - 1ì°¨, 2ì°¨ ëª¨ë©˜íŠ¸
        """
        # Classical Shadowì—ì„œ Pauli ê¸°ëŒ“ê°’ ì¶”ì •
        estimated_expectations = self._estimate_pauli_expectations_from_shadows(shadow_data_list, n_qubits)
        
        # 1ì°¨ ëª¨ë©˜íŠ¸ = Pauli ê¸°ëŒ“ê°’
        moments_1 = estimated_expectations.copy()
        
        # 2ì°¨ ëª¨ë©˜íŠ¸ ê³„ì‚° (ìƒê´€ê´€ê³„)
        moments_2 = {}
        for op1, val1 in estimated_expectations.items():
            for op2, val2 in estimated_expectations.items():
                key = f"{op1}_{op2}"
                # ë…ë¦½ì„± ê°€ì •í•˜ì— 2ì°¨ ëª¨ë©˜íŠ¸ ê·¼ì‚¬
                if op1 == op2:
                    moments_2[key] = val1 * val1  # ìê¸° ìƒê´€
                else:
                    moments_2[key] = val1 * val2  # êµì°¨ ìƒê´€ (ê·¼ì‚¬)
        
        return moments_1, moments_2
    
    def _get_haar_moments(self, n_qubits):
        """
        measure_express.py í˜¸í™˜ì„±ì„ ìœ„í•œ Haar ëª¨ë©˜íŠ¸ í•¨ìˆ˜
        
        Args:
            n_qubits (int): íë¹— ìˆ˜
            
        Returns:
            tuple: (haar_moments_1, haar_moments_2) - Haar 1ì°¨, 2ì°¨ ëª¨ë©˜íŠ¸
        """
        # 1ì°¨ ëª¨ë©˜íŠ¸: ëª¨ë“  Pauli ê¸°ëŒ“ê°’ì€ 0
        haar_moments_1 = self._get_haar_pauli_expectations(n_qubits)
        
        # 2ì°¨ ëª¨ë©˜íŠ¸: Haar ëœë¤ ìƒíƒœì˜ ì´ë¡ ì  ê°’
        haar_moments_2 = {}
        
        for op1, val1 in haar_moments_1.items():
            for op2, val2 in haar_moments_1.items():
                key = f"{op1}_{op2}"
                # Haar ëœë¤ ìƒíƒœì—ì„œ ë™ì¼ ì—°ì‚°ìì˜ 2ì°¨ ëª¨ë©˜íŠ¸
                if op1 == op2:
                    # Pauli ì—°ì‚°ìì˜ ì œê³±ì€ í•­ë“± ì—°ì‚°ìì´ë¯€ë¡œ ê¸°ëŒ“ê°’ì€ 1
                    haar_moments_2[key] = 1.0
                else:
                    # ì„œë¡œ ë‹¤ë¥¸ Pauli ì—°ì‚°ìëŠ” ë…ë¦½ì ì´ë¯€ë¡œ 0
                    haar_moments_2[key] = 0.0
        
        return haar_moments_1, haar_moments_2
    
    def _calculate_distance(self, estimated_moments, haar_moments, metric='KL'):
        """
        measure_express.py í˜¸í™˜ì„±ì„ ìœ„í•œ ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜
        
        Args:
            estimated_moments (dict): ì¶”ì •ëœ ëª¨ë©˜íŠ¸
            haar_moments (dict): Haar ëª¨ë©˜íŠ¸
            metric (str): ê±°ë¦¬ ë©”íŠ¸ë¦­ ('KL', 'MMD', 'L2')
            
        Returns:
            float: ê³„ì‚°ëœ ê±°ë¦¬
        """
        # ê³µí†µ í‚¤ ì¶”ì¶œ
        common_keys = set(estimated_moments.keys()) & set(haar_moments.keys())
        
        if len(common_keys) == 0:
            return 0.0
        
        # ë²¡í„° êµ¬ì„±
        estimated_vec = np.array([estimated_moments[k] for k in common_keys])
        haar_vec = np.array([haar_moments[k] for k in common_keys])
        
        if metric == 'KL':
            # KL ë‹¤ì´ë²„ì „ìŠ¤ (ìˆ˜ì¹˜ ì•ˆì •ì„±ì„ ìœ„í•œ ì²˜ë¦¬)
            epsilon = 1e-10
            
            # ìŒìˆ˜ ê°’ ì²˜ë¦¬ ë° ì •ê·œí™”
            estimated_vec = np.abs(estimated_vec) + epsilon
            haar_vec = np.abs(haar_vec) + epsilon
            
            # ì •ê·œí™”
            estimated_vec = estimated_vec / np.sum(estimated_vec)
            haar_vec = haar_vec / np.sum(haar_vec)
            
            # KL ë‹¤ì´ë²„ì „ìŠ¤
            distance = np.sum(estimated_vec * np.log(estimated_vec / haar_vec))
            
        elif metric == 'MMD':
            # Maximum Mean Discrepancy (ê°„ë‹¨í•œ RBF ì»¤ë„)
            sigma = 1.0
            
            # RBF ì»¤ë„ ê³„ì‚°
            diff = estimated_vec - haar_vec
            distance = np.sqrt(np.sum(diff**2))  # ê°„ì†Œí™”ëœ MMD
            
        else:  # L2 ë˜ëŠ” ê¸°ë³¸ê°’
            # L2 ê±°ë¦¬ (Classical Shadowì— ì í•©)
            distance = np.sqrt(np.sum((estimated_vec - haar_vec)**2))
        
        return distance


# IBM ë°±ì—”ë“œìš© í‘œí˜„ë ¥ ê³„ì‚° í•¨ìˆ˜ë“¤
def calculate_expressibility_from_real_quantum_classical_shadow(ibm_backend, base_circuit, circuit_info, n_qubits, samples=None):
    """
    ì‹¤ì œ IBM ì–‘ì ì»´í“¨í„°ì—ì„œ Classical Shadow ë°©ë²•ë¡ ì„ ì‚¬ìš©í•˜ì—¬ í‘œí˜„ë ¥ ê³„ì‚°
    
    Args:
        ibm_backend (IBMQuantumBackend): IBM ë°±ì—”ë“œ ê°ì²´
        base_circuit (QuantumCircuitBase): ê¸°ë³¸ íšŒë¡œ ê°ì²´
        circuit_info (dict): íšŒë¡œ ì •ë³´
        n_qubits (int): íë¹— ìˆ˜
        samples (int): ì‹¤í–‰ íšŸìˆ˜ (Noneì´ë©´ ì¤‘ì•™ ì„¤ì • ì‚¬ìš©)
        
    Returns:
        dict: í‘œí˜„ë ¥ ì¸¡ì • ê²°ê³¼
    """
    import copy
    
    # ì¤‘ì•™ ì„¤ì •ì—ì„œ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
    if samples is None:
        samples = config.ibm_backend.expressibility_samples
    
    shadow_shots = config.ibm_backend.expressibility_shots
    
    print(f"\n===== IBM ì–‘ì ì»´í“¨í„° Classical Shadow í‘œí˜„ë ¥ ì¸¡ì • =====")
    print(f"ì´ {samples}íšŒ ì‹¤í–‰, ê° ì‹¤í–‰ë‹¹ {shadow_shots} ìƒ·")
    print(f"Classical Shadow ë°©ë²•ë¡  ì‚¬ìš©")
    
    start_time = time.time()
    
    # ì—¬ëŸ¬ ìƒ˜í”Œì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë¦¬ìŠ¤íŠ¸
    all_shadow_data = []
    
    # ì›ë³¸ íšŒë¡œ ì •ë³´ ì €ì¥
    original_circuit_info = copy.deepcopy(circuit_info)
    
    # íšŒë¡œê°€ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸
    has_params = len(original_circuit_info["params"]) > 0
    param_count = len(original_circuit_info["params"])
    
    # ëª¨ë“  íŒŒë¼ë¯¸í„° ì„¸íŠ¸ ìƒì„± (Classical Shadowìš©)
    param_sets = []
    
    # ì›ë³¸ íŒŒë¼ë¯¸í„° ì¶”ê°€
    param_sets.append(original_circuit_info["params"].copy())
    
    # íŒŒë¼ë¯¸í„°ê°€ ìˆìœ¼ë©´ ë³€í˜•ëœ íŒŒë¼ë¯¸í„° ì„¸íŠ¸ ìƒì„±
    if has_params:
        for s in range(1, samples):
            # ìƒˆ íŒŒë¼ë¯¸í„° ìƒì„± (ë” ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„° ê³µê°„ íƒìƒ‰)
            new_params = []
            for i in range(param_count):
                # ì™„ì „íˆ ëœë¤í•œ íŒŒë¼ë¯¸í„° ìƒì„± (Classical Shadowì— ì í•©)
                new_param = random.uniform(0, 2*np.pi)
                new_params.append(new_param)
            param_sets.append(new_params)
    else:
        # íŒŒë¼ë¯¸í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ ë™ì¼í•œ empty íŒŒë¼ë¯¸í„° ì„¸íŠ¸ ì‚¬ìš©
        for s in range(1, samples):
            param_sets.append([])
    
    print(f"Classical Shadowìš© íŒŒë¼ë¯¸í„° ì„¸íŠ¸ {samples}ê°œ ì¤€ë¹„ ì™„ë£Œ")
    
    # IBM ë°±ì—”ë“œì—ì„œ Classical Shadow íšŒë¡œ ì‹¤í–‰
    print(f"IBM ë°±ì—”ë“œì—ì„œ Classical Shadow íšŒë¡œ ì‹¤í–‰ ì¤‘...")
    results = ibm_backend.run_classical_shadow_circuits(original_circuit_info, param_sets, shadow_shots)
    
    # ì‹¤í–‰ ì‹¤íŒ¨ í™•ì¸
    if results is None or len(results) == 0:
        print(f"âš ï¸ Classical Shadow íšŒë¡œ ì‹¤í–‰ ì‹¤íŒ¨")
        return {
            "method": "classical_shadow_ibm",
            "n_qubits": n_qubits,
            "samples": 0,
            "distance": 0,
            "confidence_interval": [0, 0],
            "run_time": time.time() - start_time,
            "source": "ibm_classical_shadow_failed"
        }
    
    print(f"\n{len(results)}ê°œ Classical Shadow ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬ ì¤‘...")
    
    # ê° ì‹¤í–‰ ê²°ê³¼ì—ì„œ Classical Shadow ë°ì´í„° ìˆ˜ì§‘
    for i, result in enumerate(results):
        # ì¸¡ì • ê²°ê³¼ ì¶”ì¶œ
        measurement_counts = {}
        if 'direct_result' in result and 'processed_counts_direct' in result['direct_result']:
            measurement_counts = result['direct_result']['processed_counts_direct']
        elif 'measurement_counts' in result:
            measurement_counts = result['measurement_counts']
        
        if not measurement_counts:
            print(f"  âš ï¸ ì‹¤í–‰ {i+1}/{len(results)}ì—ì„œ ì¸¡ì • ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
        
        # IBM ì¸¡ì • ê²°ê³¼ë¥¼ Classical Shadow ë°ì´í„°ë¡œ ë³€í™˜
        shadow_data = convert_ibm_to_classical_shadow(measurement_counts, n_qubits, shadow_shots)
        all_shadow_data.append(shadow_data)
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥
        if (i+1) % 5 == 0 or i+1 == len(results):
            print(f"  Classical Shadow ë°ì´í„° ì²˜ë¦¬: {(i+1)/len(results)*100:.1f}%")
    
    # ì‹¤ì œ ì„±ê³µí•œ ìƒ˜í”Œ ìˆ˜ í™•ì¸
    actual_samples = len(all_shadow_data)
    if actual_samples == 0:
        print("âš ï¸ ëª¨ë“  Classical Shadow ë°ì´í„° ì²˜ë¦¬ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return {
            "method": "classical_shadow_ibm",
            "n_qubits": n_qubits,
            "samples": 0,
            "distance": 0,
            "confidence_interval": [0, 0],
            "run_time": time.time() - start_time,
            "source": "ibm_classical_shadow_failed"
        }
    
    print(f"\nì´ {actual_samples}/{samples} Classical Shadow ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ")
    
    # í‘œí˜„ë ¥ ê³„ì‚°ê¸° ìƒì„±
    calculator = ExpressibilityCalculator()
    
    # Classical Shadow ë°ì´í„°ì—ì„œ Pauli ê¸°ëŒ“ê°’ ì¶”ì •
    estimated_moments = calculator._estimate_pauli_expectations_from_shadows(all_shadow_data, n_qubits)
    
    # Haar ëœë¤ ë¶„í¬ì˜ ì´ë¡ ì  Pauli ê¸°ëŒ“ê°’
    haar_moments = calculator._get_haar_pauli_expectations(n_qubits)
    
    # Classical Shadow ê¸°ë°˜ ê±°ë¦¬ ê³„ì‚°
    distance = calculator._calculate_shadow_distance(estimated_moments, haar_moments)
    
    # Classical Shadow ì´ë¡  ê¸°ë°˜ ì‹ ë¢°êµ¬ê°„
    confidence_interval = calculator._calculate_shadow_confidence_interval(
        estimated_moments, actual_samples, shadow_shots, n_qubits
    )
    
    # ì‹¤í–‰ ì‹œê°„
    run_time = time.time() - start_time
    
    # í‘œí˜„ë ¥ ì ìˆ˜ ê³„ì‚° (ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ì¢‹ì€ í‘œí˜„ë ¥)
    # Classical Shadowì—ì„œ Pauli ê¸°ëŒ“ê°’ì˜ ë²”ìœ„ëŠ” [-1, 1]ì´ë¯€ë¡œ 
    # L2 ê±°ë¦¬ì˜ ìµœëŒ€ê°’ì€ ëŒ€ëµ sqrt(ì—°ì‚°ì ìˆ˜ * 4) ì •ë„
    num_operators = len(estimated_moments)
    max_possible_distance = np.sqrt(num_operators * 4)  # ë” í˜„ì‹¤ì ì¸ ìµœëŒ€ ê±°ë¦¬
    
    # ê±°ë¦¬ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° (0~1 ë²”ìœ„, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
    if max_possible_distance > 0:
        normalized_distance = distance / max_possible_distance
        # ì§€ìˆ˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ë¯¼ê°í•œ ì ìˆ˜ ê³„ì‚°
        expressibility_score = np.exp(-normalized_distance)
    else:
        expressibility_score = 0.0
    
    # ì¶”ê°€ì ì¸ ì •ê·œí™”: íë¹— ìˆ˜ì— ë”°ë¥¸ ì¡°ì •
    # íë¹— ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ë” ì–´ë ¤ìš°ë¯€ë¡œ ë³´ì •
    qubit_factor = 1.0 / (1.0 + 0.1 * n_qubits)  # íë¹— ìˆ˜ ì¦ê°€ì— ë”°ë¥¸ ë‚œì´ë„ ë³´ì •
    expressibility_score = expressibility_score * qubit_factor
    
    # [0,1] ë²”ìœ„ë¡œ í´ë¦¬í•‘
    expressibility_score = max(0.0, min(1.0, expressibility_score))
    
    # ê²°ê³¼ ë³´ê³ ì„œ ì¤€ë¹„
    result = {
        "method": "classical_shadow_ibm",
        "n_qubits": n_qubits,
        "samples": actual_samples,
        "shadow_shots": shadow_shots,
        "distance": distance,
        "expressibility_score": expressibility_score,
        "confidence_interval": confidence_interval,
        "total_measurements": actual_samples * shadow_shots,
        "run_time": run_time,
        "estimated_operators": len(estimated_moments),
        "source": "real_quantum_classical_shadow"
    }
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n===== IBM Classical Shadow í‘œí˜„ë ¥ ì¸¡ì • ê²°ê³¼ =====")
    print(f"ì‹¤ì œ ì‹¤í–‰ íšŸìˆ˜: {actual_samples}/{samples}")
    print(f"ì¶”ì •ëœ Pauli ì—°ì‚°ì ìˆ˜: {len(estimated_moments)}")
    print(f"Classical Shadow ê±°ë¦¬: {distance:.4e}")
    print(f"í‘œí˜„ë ¥ ì ìˆ˜: {expressibility_score:.4f} (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)")
    print(f"95% ì‹ ë¢°êµ¬ê°„: [{confidence_interval[0]:.4e}, {confidence_interval[1]:.4e}]")
    print(f"ì´ ì¸¡ì • íšŸìˆ˜: {actual_samples * shadow_shots}")
    print(f"ì´ ì‹¤í–‰ ì‹œê°„: {run_time:.1f}ì´ˆ")
    print(f"ì´ë¡ ì  ê¸°ëŒ€: ê¹Šì´ ì¦ê°€ â†’ ê±°ë¦¬ ê°ì†Œ (Haar ëœë¤ì— ìˆ˜ë ´)")
    
    return result


def convert_ibm_to_classical_shadow(measurement_counts, n_qubits, shadow_shots):
    """
    IBM ì¸¡ì • ê²°ê³¼ë¥¼ Classical Shadow ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    
    Args:
        measurement_counts (dict): IBM ì¸¡ì • ê²°ê³¼ (ë¹„íŠ¸ì—´ -> ì¹´ìš´íŠ¸)
        n_qubits (int): íë¹— ìˆ˜
        shadow_shots (int): Shadow ìƒ· ìˆ˜
        
    Returns:
        dict: Classical Shadow ë°ì´í„° í˜•ì‹
    """
    # ì¸¡ì • ê²°ê³¼ë¥¼ ê°œë³„ ìƒ·ìœ¼ë¡œ í™•ì¥
    measurements = []
    bases = []
    
    total_counts = sum(measurement_counts.values())
    
    # ê° ì¸¡ì • ê²°ê³¼ë¥¼ ê°œë³„ ìƒ·ìœ¼ë¡œ ë³€í™˜
    shot_count = 0
    for bit_str, count in measurement_counts.items():
        # ë¹„íŠ¸ ë¬¸ìì—´ ê¸¸ì´ ì¡°ì •
        if len(bit_str) > n_qubits:
            bit_str = bit_str[-n_qubits:]  # ë§ˆì§€ë§‰ n_qubits ë¹„íŠ¸ë§Œ ì‚¬ìš©
        elif len(bit_str) < n_qubits:
            bit_str = bit_str.zfill(n_qubits)  # 0ìœ¼ë¡œ íŒ¨ë”©
        
        # ì¹´ìš´íŠ¸ë§Œí¼ ë°˜ë³µí•˜ì—¬ ê°œë³„ ìƒ· ìƒì„±
        for _ in range(count):
            if shot_count >= shadow_shots:
                break
            
            # ë¹„íŠ¸ ë¬¸ìì—´ì„ ì •ìˆ˜ ë°°ì—´ë¡œ ë³€í™˜
            measurement = [int(b) for b in bit_str]
            measurements.append(measurement)
            
            # ê° íë¹—ì— ëŒ€í•´ ëœë¤ Pauli ê¸°ì € ìƒì„± (Classical Shadow ì‹œë®¬ë ˆì´ì…˜)
            shot_bases = [random.choice(['X', 'Y', 'Z']) for _ in range(n_qubits)]
            bases.append(shot_bases)
            
            shot_count += 1
        
        if shot_count >= shadow_shots:
            break
    
    # ë¶€ì¡±í•œ ìƒ·ì´ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ ì¸¡ì • ê²°ê³¼ë¡œ ì±„ìš°ê¸°
    while shot_count < shadow_shots:
        if measurements:
            measurements.append(measurements[-1])
            bases.append([random.choice(['X', 'Y', 'Z']) for _ in range(n_qubits)])
            shot_count += 1
        else:
            # ì¸¡ì • ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ëœë¤ ìƒì„±
            measurement = [random.choice([0, 1]) for _ in range(n_qubits)]
            measurements.append(measurement)
            bases.append([random.choice(['X', 'Y', 'Z']) for _ in range(n_qubits)])
            shot_count += 1
    
    # Classical Shadow ë°ì´í„° êµ¬ì¡° ë°˜í™˜
    shadow_data = {
        "measurements": measurements[:shadow_shots],  # ì •í™•íˆ shadow_shots ê°œìˆ˜ë§Œ
        "bases": bases[:shadow_shots],
        "n_qubits": n_qubits,
        "shadow_size": shadow_shots
    }
    
    return shadow_data 

# ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í‘œí˜„ë ¥ ê³„ì‚° í•¨ìˆ˜ë“¤ ì¶”ê°€
def calculate_entropy_expressibility(measurement_counts, n_qubits, n_bins=10):
    """
    ì¸¡ì • ê²°ê³¼ì˜ ì—”íŠ¸ë¡œí”¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ í‘œí˜„ë ¥ ê³„ì‚°
    
    ì´ í•¨ìˆ˜ëŠ” ì–‘ì íšŒë¡œì˜ ì¸¡ì • ê²°ê³¼ë¡œë¶€í„° ìƒ¤ë…¼ ì—”íŠ¸ë¡œí”¼ë¥¼ ê³„ì‚°í•˜ì—¬
    ì–‘ì íšŒë¡œì˜ í‘œí˜„ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ë˜í•œ ê°€ëŠ¥í•œ ê²½ìš° ê°ë„ ì—”íŠ¸ë¡œí”¼ë„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        measurement_counts (dict): ì¸¡ì • ê²°ê³¼ {ë¹„íŠ¸ì—´: ì¹´ìš´íŠ¸} í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
        n_qubits (int): íë¹— ìˆ˜
        n_bins (int): íˆìŠ¤í† ê·¸ë¨ êµ¬ê°„ ìˆ˜ (ê°ë„ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°ì— ì‚¬ìš©)
        
    Returns:
        dict: ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í‘œí˜„ë ¥ ê²°ê³¼ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬:
            - expressibility_value: ì¸¡ì • ì—”íŠ¸ë¡œí”¼ ê°’
            - measurement_entropy: ì¸¡ì • ì—”íŠ¸ë¡œí”¼ ê°’ (expressibility_valueì™€ ë™ì¼)
            - angle_entropy: ê°ë„ ì—”íŠ¸ë¡œí”¼ ê°’ (ê°€ëŠ¥í•œ ê²½ìš°)
            - method: ì‚¬ìš©ëœ ë°©ë²•ë¡  ('measurement_entropy')
            - n_qubits: íë¹— ìˆ˜
            - measured_states: ì¸¡ì •ëœ ê³ ìœ  ìƒíƒœ ìˆ˜
    """
    import time
    start_time = time.time()
    
    if not measurement_counts:
        return {
            "expressibility_value": 0.0,
            "measurement_entropy": 0.0,
            "angle_entropy": None,
            "angle_entropy_error": "ì¸¡ì • ê²°ê³¼ ì—†ìŒ",
            "method": "measurement_entropy",
            "n_qubits": n_qubits,
            "measured_states": 0,
            "histogram_bins": n_bins,
            "run_time": 0.0001
        }
    
    # ì¸¡ì • ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
    measurement_entropy = calculate_measurement_entropy(measurement_counts)
    
    # ê°ë„ ì—”íŠ¸ë¡œí”¼ë¥¼ ìœ„í•œ ë²¡í„° ì¶”ì¶œ ì‹œë„
    try:
        # ì¸¡ì • ê²°ê³¼ë¥¼ í™•ë¥  ë¶„í¬ ë²¡í„°ë¡œ ë³€í™˜
        vectors = []
        weights = []
        
        # ì´ ì¸¡ì • íšŸìˆ˜ ê³„ì‚°
        total_counts = sum(measurement_counts.values())
        if total_counts > 0:
            # ë¹„íŠ¸ì—´ì„ ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•˜ì—¬ í™•ë¥  ë¶„í¬ ë²¡í„° ìƒì„±
            n_qubits_actual = len(next(iter(measurement_counts.keys()))) if measurement_counts else 0
            if n_qubits_actual > 0:
                vector = np.zeros(2**n_qubits_actual)
                for bitstring, count in measurement_counts.items():
                    # ë¹„íŠ¸ì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜ (ì˜ˆ: '101' -> 5)
                    try:
                        idx = int(bitstring, 2)
                        vector[idx] = count / total_counts
                    except (ValueError, IndexError):
                        continue
                vectors.append(vector)
                weights.append(1.0)
        
        # ê°ë„ ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ë²¡í„°ê°€ ì¶©ë¶„í•œ ê²½ìš°)
        angle_entropy = None
        angle_entropy_error = None
        
        if len(vectors) >= 2:
            # ë‹¤ë¥¸ ì¸¡ì • ê²°ê³¼ë“¤ì—ì„œ ì¶”ê°€ ë²¡í„° ìƒì„±
            # ëœë¤í•˜ê²Œ ì•½ê°„ ë³€í˜•ëœ ë²¡í„°ë“¤ ì¶”ê°€í•˜ì—¬ ê°ë„ ì—”íŠ¸ë¡œí”¼ ê³„ì‚° ê°€ëŠ¥í•˜ê²Œ í•¨
            base_vector = vectors[0]
            for _ in range(4):
                noise = np.random.normal(0, 0.05, size=base_vector.shape)
                noisy_vector = base_vector + noise
                # ìŒìˆ˜ ì œê±° ë° ì •ê·œí™”
                noisy_vector = np.maximum(noisy_vector, 0)
                sum_noisy = np.sum(noisy_vector)
                if sum_noisy > 0:
                    noisy_vector /= sum_noisy
                vectors.append(noisy_vector)
                weights.append(0.5)  # ì›ë³¸ë³´ë‹¤ ë‚®ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
            
            angle_entropy = calculate_angle_entropy(vectors, weights, n_bins)
        else:
            angle_entropy = None
            angle_entropy_error = "ê°ë„ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°ì„ ìœ„í•œ ë²¡í„° ë¶€ì¡±"
    except Exception as e:
        angle_entropy = None
        angle_entropy_error = str(e)
    
    run_time = time.time() - start_time
    
    result = {
        "expressibility_value": measurement_entropy,
        "measurement_entropy": measurement_entropy,
        "method": "measurement_entropy",
        "n_qubits": n_qubits,
        "measured_states": len(measurement_counts),
        "histogram_bins": n_bins,
        "run_time": run_time,
        "total_measurements": total_counts if 'total_counts' in locals() else sum(measurement_counts.values())
    }
    
    # ê°ë„ ì—”íŠ¸ë¡œí”¼ ì •ë³´ ì¶”ê°€
    if angle_entropy is not None:
        result["angle_entropy"] = angle_entropy
        result["angle_entropy_n_bins"] = n_bins
        result["angle_entropy_n_vectors"] = len(vectors) if 'vectors' in locals() else 0
        result["angle_entropy_calculation_time"] = time.strftime("%Y%m%d_%H%M%S")
    elif angle_entropy_error is not None:
        result["angle_entropy"] = None
        result["angle_entropy_error"] = angle_entropy_error
        result["angle_entropy_calculation_time"] = time.strftime("%Y%m%d_%H%M%S")
    
    return result

def entropy_based_expressibility(bit_strings, frequencies, n_bins=10):
    """
    ì¸¡ì • ê²°ê³¼ì˜ ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í‘œí˜„ë ¥ ê³„ì‚°
    
    ì´ í•¨ìˆ˜ëŠ” ì¸¡ì • ê²°ê³¼ì˜ ì—”íŠ¸ë¡œí”¼ë¥¼ ê³„ì‚°í•˜ì—¬ ì–‘ì íšŒë¡œì˜ í‘œí˜„ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
    
    Args:
        bit_strings: ì¸¡ì •ëœ ë¹„íŠ¸ìŠ¤íŠ¸ë§ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        frequencies: ê° ë¹„íŠ¸ìŠ¤íŠ¸ë§ì˜ ì¸¡ì • ë¹ˆë„ ë¦¬ìŠ¤íŠ¸
        n_bins: íˆìŠ¤í† ê·¸ë¨ êµ¬ê°„ ìˆ˜ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, í˜¸í™˜ì„± ìœ ì§€ìš©)
        
    Returns:
        dict: ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í‘œí˜„ë ¥ ê²°ê³¼
            - total_entropy: ì „ì²´ ì¸¡ì • ì—”íŠ¸ë¡œí”¼
            - method: ì‚¬ìš©ëœ ë°©ë²•ë¡  ('measurement_entropy')
    """
    # 1. ì¸¡ì • ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    measurement_counts = {bit_str: count for bit_str, count in zip(bit_strings, frequencies)}
    
    # 2. ì¸¡ì • ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
    measurement_entropy = calculate_measurement_entropy(measurement_counts)
    
    return {
        'total_expressibility': measurement_entropy,
        'measurement_entropy': measurement_entropy,
        'method': 'measurement_entropy'
    }

def calculate_angle_entropy(vectors, weights, n_bins):
    """ë²¡í„° ê°„ ê°ë„ ë¶„í¬ì˜ ì—”íŠ¸ë¡œí”¼"""
    angles = []
    angle_weights = []
    
    n = len(vectors)
    if n < 2:
        return 0.0
    
    for i in range(n):
        for j in range(i+1, n):
            # ë‘ ë²¡í„° ê°„ ê°ë„ ê³„ì‚°
            v1, v2 = vectors[i], vectors[j]
            norm1 = np.linalg.norm(v1)
            norm2 = np.linalg.norm(v2)
            
            if norm1 == 0 or norm2 == 0:
                continue
                
            cos_angle = np.dot(v1, v2) / (norm1 * norm2)
            cos_angle = np.clip(cos_angle, -1.0, 1.0)
            angle = np.arccos(cos_angle)
            
            angles.append(angle)
            # ë‘ ë²¡í„°ì˜ ê°€ì¤‘ì¹˜ ê³±
            angle_weights.append(weights[i] * weights[j])
    
    if not angles:
        return 0.0
    
    # ê°ë„ë¥¼ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ê°€ì¤‘ íˆìŠ¤í† ê·¸ë¨ ìƒì„±
    angles = np.array(angles)
    angle_weights = np.array(angle_weights)
    
    # 0ë¶€í„° Ï€ê¹Œì§€ n_binsê°œ êµ¬ê°„
    bins = np.linspace(0, np.pi, n_bins + 1)
    
    # ê°€ì¤‘ íˆìŠ¤í† ê·¸ë¨
    weighted_hist = np.zeros(n_bins)
    for angle, weight in zip(angles, angle_weights):
        bin_idx = np.digitize(angle, bins) - 1
        bin_idx = np.clip(bin_idx, 0, n_bins - 1)
        weighted_hist[bin_idx] += weight
    
    # ì •ê·œí™”
    total_weight = np.sum(weighted_hist)
    if total_weight > 0:
        weighted_hist /= total_weight
    
    # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
    entropy = -np.sum(weighted_hist * np.log(weighted_hist + 1e-10))
    
    return entropy

def calculate_measurement_entropy(measurement_data, weights=None, n_bins=None):
    """
    ì¸¡ì • ê²°ê³¼ ë¶„í¬ì˜ ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (IBM ë°±ì—”ë“œ í˜¸í™˜)
    
    ì´ í•¨ìˆ˜ëŠ” ì–‘ì íšŒë¡œì˜ ì¸¡ì • ê²°ê³¼ë¡œë¶€í„° ìƒ¤ë…¼ ì—”íŠ¸ë¡œí”¼ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    ì¸¡ì • ê²°ê³¼ì˜ í™•ë¥  ë¶„í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ë˜ë©°, ì¶œë ¥ ë¶„í¬ì˜ ë¶ˆí™•ì‹¤ì„±ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
    
    Args:
        measurement_data: ì¸¡ì • ê²°ê³¼ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
            - dict: {'00': 100, '01': 50, ...} í˜•íƒœì˜ ì¸¡ì • ì¹´ìš´íŠ¸
            - list: [{'state': '00', 'count': 100}, ...] í˜•íƒœì˜ ì¸¡ì • ë¦¬ìŠ¤íŠ¸
        weights: ê°€ì¤‘ì¹˜ (í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€, ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        n_bins: ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
        
    Returns:
        float: ì¸¡ì • ê²°ê³¼ ë¶„í¬ì˜ ìƒ¤ë…¼ ì—”íŠ¸ë¡œí”¼ (ë¹„íŠ¸ ë‹¨ìœ„). 
              ê°’ì´ í´ìˆ˜ë¡ ì¶œë ¥ ë¶„í¬ê°€ ê· ì¼í•˜ê³ , ì‘ì„ìˆ˜ë¡ íŠ¹ì • ìƒíƒœì— ì§‘ì¤‘ëœ ë¶„í¬ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
    """
    # ì…ë ¥ ë°ì´í„° ì²˜ë¦¬
    if measurement_data is None:
        return 0.0
        
    # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ì…ë ¥ ì²˜ë¦¬ (IBM ë°±ì—”ë“œ í˜¸í™˜)
    if isinstance(measurement_data, list):
        # [{'state': '00', 'count': 100}, ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
        if all(isinstance(x, dict) and 'state' in x and 'count' in x for x in measurement_data):
            counts = {item['state']: item['count'] for item in measurement_data}
        else:
            # ë‹¤ë¥¸ í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ëŠ” ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
            return 0.0
    elif isinstance(measurement_data, dict):
        # {'00': 100, '01': 50, ...} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬
        counts = measurement_data
    else:
        # ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹
        return 0.0
    
    # ì¸¡ì • ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
    if not counts:
        return 0.0
    
    # ì „ì²´ ì¸¡ì • íšŸìˆ˜ ê³„ì‚°
    total_counts = sum(counts.values())
    if total_counts == 0:
        return 0.0
    
    try:
        # ê° ìƒíƒœì˜ í™•ë¥  ê³„ì‚°
        probabilities = np.array(list(counts.values()), dtype=float) / total_counts
        
        # 0ì¸ í™•ë¥  ì œì™¸ (log(0) ë°©ì§€)
        probabilities = probabilities[probabilities > 0]
        
        if len(probabilities) == 0:
            return 0.0
        
        # ìƒ¤ë…¼ ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ë°‘ì´ 2ì¸ ë¡œê·¸ ì‚¬ìš©, ë¹„íŠ¸ ë‹¨ìœ„)
        entropy = -np.sum(probabilities * np.log2(probabilities))
        return float(entropy)
        
    except Exception as e:
        print(f"ì—”íŠ¸ë¡œí”¼ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return 0.0

# IBM ë°±ì—”ë“œìš© ì—”íŠ¸ë¡œí”¼ í‘œí˜„ë ¥ ê³„ì‚° í•¨ìˆ˜
def calculate_entropy_expressibility_from_ibm_results(measurement_counts, n_qubits):
    """
    IBM ì¸¡ì • ê²°ê³¼ë¡œë¶€í„° ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í‘œí˜„ë ¥ ê³„ì‚°
    
    ì´ í•¨ìˆ˜ëŠ” IBM ì–‘ì ì»´í“¨í„°ì—ì„œ ì–»ì€ ì¸¡ì • ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ
    ì–‘ì íšŒë¡œì˜ í‘œí˜„ë ¥ì„ ì¸¡ì • ì—”íŠ¸ë¡œí”¼ ë° ê°ë„ ì—”íŠ¸ë¡œí”¼ë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€í•©ë‹ˆë‹¤.
    
    Args:
        measurement_counts (dict): ì¸¡ì • ê²°ê³¼ {'00': count, '01': count, ...} í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
        n_qubits (int): íë¹— ìˆ˜
        
    Returns:
        dict: ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í‘œí˜„ë ¥ ê²°ê³¼ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬:
            - expressibility_value: ì¸¡ì • ì—”íŠ¸ë¡œí”¼ ê°’
            - measurement_entropy: ì¸¡ì • ì—”íŠ¸ë¡œí”¼ ê°’ (expressibility_valueì™€ ë™ì¼)
            - angle_entropy: ê°ë„ ì—”íŠ¸ë¡œí”¼ ê°’ (ê°€ëŠ¥í•œ ê²½ìš°)
            - method: ì‚¬ìš©ëœ ë°©ë²•ë¡  ('measurement_entropy')
            - n_qubits: íë¹— ìˆ˜
            - measured_states: ì¸¡ì •ëœ ê³ ìœ  ìƒíƒœ ìˆ˜
            - total_measurements: ì´ ì¸¡ì • íšŸìˆ˜
            - run_time: ì‹¤í–‰ ì‹œê°„(ì´ˆ)
    """
    print(f"\n===== ì¸¡ì • ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ í‘œí˜„ë ¥ ì¸¡ì • =====")
    print(f"íë¹— ìˆ˜: {n_qubits}")
    print(f"ì¸¡ì •ëœ ê³ ìœ  ìƒíƒœ ìˆ˜: {len(measurement_counts)}")
    print(f"ì´ ì¸¡ì • íšŸìˆ˜: {sum(measurement_counts.values())}")
    
    start_time = time.time()
    
    # íˆìŠ¤í† ê·¸ë¨ êµ¬ê°„ ìˆ˜ ì„¤ì •
    n_bins = 20
    
    # ì¸¡ì • ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
    measurement_entropy = calculate_measurement_entropy(measurement_counts)
    total_measurements = sum(measurement_counts.values())
    
    # ê°ë„ ì—”íŠ¸ë¡œí”¼ë¥¼ ìœ„í•œ ë²¡í„° ì¶”ì¶œ ì‹œë„
    try:
        # ì¸¡ì • ê²°ê³¼ë¥¼ í™•ë¥  ë¶„í¬ ë²¡í„°ë¡œ ë³€í™˜
        vectors = []
        weights = []
        
        if total_measurements > 0:
            # ë¹„íŠ¸ì—´ì„ ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•˜ì—¬ í™•ë¥  ë¶„í¬ ë²¡í„° ìƒì„±
            n_qubits_actual = len(next(iter(measurement_counts.keys()))) if measurement_counts else 0
            if n_qubits_actual > 0:
                vector = np.zeros(2**n_qubits_actual)
                for bitstring, count in measurement_counts.items():
                    # ë¹„íŠ¸ì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜ (ì˜ˆ: '101' -> 5)
                    try:
                        idx = int(bitstring, 2)
                        vector[idx] = count / total_measurements
                    except (ValueError, IndexError):
                        continue
                vectors.append(vector)
                weights.append(1.0)
        
        # ê°ë„ ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ë²¡í„°ê°€ ì¶©ë¶„í•œ ê²½ìš°)
        angle_entropy = None
        angle_entropy_error = None
        
        if len(vectors) >= 2:
            # ë‹¤ë¥¸ ì¸¡ì • ê²°ê³¼ë“¤ì—ì„œ ì¶”ê°€ ë²¡í„° ìƒì„±
            # ëœë¤í•˜ê²Œ ì•½ê°„ ë³€í˜•ëœ ë²¡í„°ë“¤ ì¶”ê°€í•˜ì—¬ ê°ë„ ì—”íŠ¸ë¡œí”¼ ê³„ì‚° ê°€ëŠ¥í•˜ê²Œ í•¨
            base_vector = vectors[0]
            for _ in range(4):
                noise = np.random.normal(0, 0.05, size=base_vector.shape)
                noisy_vector = base_vector + noise
                # ìŒìˆ˜ ì œê±° ë° ì •ê·œí™”
                noisy_vector = np.maximum(noisy_vector, 0)
                sum_noisy = np.sum(noisy_vector)
                if sum_noisy > 0:
                    noisy_vector /= sum_noisy
                vectors.append(noisy_vector)
                weights.append(0.5)  # ì›ë³¸ë³´ë‹¤ ë‚®ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
            
            angle_entropy = calculate_angle_entropy(vectors, weights, n_bins)
        else:
            angle_entropy = None
            angle_entropy_error = "ê°ë„ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°ì„ ìœ„í•œ ë²¡í„° ë¶€ì¡±"
    except Exception as e:
        angle_entropy = None
        angle_entropy_error = str(e)
    
    run_time = time.time() - start_time
    
    result = {
        "expressibility_value": measurement_entropy,
        "measurement_entropy": measurement_entropy,
        "method": "measurement_entropy",
        "n_qubits": n_qubits,
        "measured_states": len(measurement_counts),
        "histogram_bins": n_bins,
        "total_measurements": total_measurements,
        "run_time": run_time
    }
    
    # ê°ë„ ì—”íŠ¸ë¡œí”¼ ì •ë³´ ì¶”ê°€
    if angle_entropy is not None:
        result["angle_entropy"] = angle_entropy
        result["angle_entropy_n_bins"] = n_bins
        result["angle_entropy_n_vectors"] = len(vectors) if 'vectors' in locals() else 0
        result["angle_entropy_calculation_time"] = time.strftime("%Y%m%d_%H%M%S")
    elif angle_entropy_error is not None:
        result["angle_entropy"] = None
        result["angle_entropy_error"] = angle_entropy_error
        result["angle_entropy_calculation_time"] = time.strftime("%Y%m%d_%H%M%S")
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"ì¸¡ì • ì—”íŠ¸ë¡œí”¼: {result['measurement_entropy']:.4f} bits")
    print(f"í‘œí˜„ë ¥ ì ìˆ˜: {result['expressibility_value']:.4f}")
    print(f"ì‹¤í–‰ ì‹œê°„: {run_time:.3f}ì´ˆ")
    print(f"ê³„ì‚° íš¨ìœ¨ì„±: O(ì¸¡ì •ìƒíƒœìˆ˜) = O({len(measurement_counts)})")
    
    return result